{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de0abdcf",
   "metadata": {},
   "source": [
    "# Entrenamiento y evaluación de modelos\n",
    "## Contratación de Seguros de Viajes  \n",
    "  \n",
    "  \n",
    "  \n",
    "#### Preprocesamiento de los datos  \n",
    "Como primera instancia, aplicamos las transformaciones sobre el dataset que indicamos en el trabajo práctico anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf5c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las dependencias necesarias.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn_pandas\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import learning_curve\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e7dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el dataset.\n",
    "dataset = pd.read_csv('TravelInsurancePrediction.csv')\n",
    "\n",
    "# Renombramos las variables.\n",
    "dataset = dataset.rename(columns={'Idx':'idx', 'Age':'age', 'Employment Type':'employment_type', 'GraduateOrNot':'graduate_or_not', 'AnnualIncome':'annual_income', 'FamilyMembers':'family_members', 'ChronicDiseases':'chronic_diseases', 'EverTravelledAbroad':'ever_travelled_abroad', 'FrequentFlyer':'frequent_flyer', 'TravelInsurance':'travel_insurance'})\n",
    "\n",
    "# Seleccionamos la primer columna 'idx', como índice.\n",
    "dataset = dataset.set_index(\"idx\")\n",
    "\n",
    "# Reemplazamos los valores 'Yes' y 'No' por 0 y 1 de las variables indicadas en el tp1.\n",
    "dataset[\"graduate_or_not\"] = dataset.graduate_or_not.replace(['No', 'Yes'], [0,1])\n",
    "dataset[\"frequent_flyer\"] = dataset.frequent_flyer.replace(['No', 'Yes'], [0,1])\n",
    "dataset[\"ever_travelled_abroad\"] = dataset.ever_travelled_abroad.replace(['No', 'Yes'], [0,1])\n",
    "\n",
    "# Reemplazamos los dos posibles valores de la columna 'employment_type' por 0 y 1.\n",
    "dataset[\"employment_type\"] = dataset.employment_type.replace(['Private Sector/Self Employed', 'Government Sector'], [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674cf9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos el dataset en train (60%), test (20%) y validation (20%)\n",
    "train, not_train = train_test_split(dataset, test_size=0.4, random_state=42)\n",
    "validation, test = train_test_split(not_train, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamos las variables numéricas.\n",
    "mapper_scaller = DataFrameMapper([\n",
    "    (['age'],[MinMaxScaler()]),\n",
    "    (['employment_type'],None),\n",
    "    (['graduate_or_not'],None),\n",
    "    (['annual_income'],[MinMaxScaler()]),\n",
    "    (['family_members'],[MinMaxScaler()]),\n",
    "    (['chronic_diseases'],None),\n",
    "    (['frequent_flyer'],None),\n",
    "    (['ever_travelled_abroad'],None)\n",
    "])\n",
    "\n",
    "mapper_scaller.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eab37b",
   "metadata": {},
   "source": [
    "#### Elección de una métrica  \n",
    "La métrica que utilizaremos es Accuracy, debido a que permite medir el porcentaje de casos acertados en la predicción, siendo un concepto simple de explicar al cliente que requiere el modelo. Además es útil especialmente en problemas de clasificación, como es este caso.  \n",
    "Por otra parte, a modo de uso interno, también podríamos tener en cuenta la métrica llamada Precission, ya que a pesar de que la misma no sería comunicada al cliente directamente para evitar confundirlo con conceptos un tanto abstractos, nos permitiría tener en cuenta los casos de 'falsos positivos'. Estos casos serían personas que el modelo predice como potenciales compradoras del seguro pero que en la realidad no lo son, y es importante conocerlos debido a que implicarían una posible pérdida de dinero para la empresa al no realizar mayores intentos de convencerlos de lo contrario, por pensar que no lo necesitan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09651711",
   "metadata": {},
   "source": [
    "#### Elección de una técnica de feature engineering  \n",
    "Teniendo en cuenta las técnicas vistas en clase, decidimos optar por crear una nueva feature extrayendo información de la columna 'annual_income', con el objetivo de simplificar los datos para el modelo. La idea sería categorizar a los ejemplos entre clientes de clases alta, media y baja, en función de sus ingresos. Según diversas fuentes consultadas, consideramos a la clase media como aquellos que poseen ingresos anuales entre 400.000 rupias y 1.200.000 rupias. Por encima de ese rango serían personas de clase alta, y por debajo, clase baja.  \n",
    "Luego de ésto al tener una columna con variables categóricas, aplicaríamos la técnica 'One-Hot Encoder' para convertirla en 3 columnas binarias que tomen valores '0' o '1', indicando si es de esa clase o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8265ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que devuelve la clase social en función de los ingresos.\n",
    "def get_social_class(row):\n",
    "    if(row['annual_income'] > 1200000):\n",
    "        return 'alta'\n",
    "    elif(row['annual_income'] < 400000):\n",
    "        return 'baja'\n",
    "    else:\n",
    "        return 'media'\n",
    "    \n",
    "# Agregamos la nueva columna al dataset.\n",
    "social_class = dataset.apply(get_social_class,axis=1)\n",
    "dataset_with_fe = dataset\n",
    "dataset_with_fe['social_class'] = social_class\n",
    "\n",
    "dataset_with_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bcc999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos el dataset en train (60%), test (20%) y validation (20%)\n",
    "train_fe, not_train_fe = train_test_split(dataset_with_fe, test_size=0.4, random_state=42)\n",
    "validation_fe, test_fe = train_test_split(not_train_fe, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32beab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamos las variables numéricas.\n",
    "mapper_fe = DataFrameMapper([\n",
    "    (['age'],[MinMaxScaler()]),\n",
    "    (['employment_type'],None),\n",
    "    (['graduate_or_not'],None),\n",
    "    (['annual_income'],[MinMaxScaler()]),\n",
    "    (['family_members'],[MinMaxScaler()]),\n",
    "    (['chronic_diseases'],None),\n",
    "    (['frequent_flyer'],None),\n",
    "    (['ever_travelled_abroad'],None),\n",
    "    (['social_class'],[OneHotEncoder()])\n",
    "])\n",
    "\n",
    "mapper_fe.fit(train_fe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760c1a76",
   "metadata": {},
   "source": [
    "#### Entrenamiento y evaluación de modelos  \n",
    "Para este dataset seleccionamos los siguientes modelos:\n",
    "* k-Nearest Neighbors o k-NNN (vecinos cercanos)\n",
    "* Decision Tree (árbol de decisión)\n",
    "* Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evaluar modelos (sin feature engineering).\n",
    "def evaluate_model(model, set_names=('train', 'validation'), title=''):\n",
    "    if title:\n",
    "        display(title)\n",
    "        \n",
    "    final_metrics = defaultdict(list)\n",
    "    \n",
    "    for i, set_name in enumerate(set_names):\n",
    "        assert set_name in ['train', 'validation', 'test']\n",
    "        set_data = globals()[set_name] \n",
    "\n",
    "        y = set_data.travel_insurance\n",
    "        y_pred = model.predict(set_data)\n",
    "        final_metrics['Accuracy'].append(metrics.accuracy_score(y, y_pred))\n",
    "        final_metrics['Precision'].append(metrics.precision_score(y, y_pred))\n",
    "        \n",
    "    display(pd.DataFrame(final_metrics, index=set_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d008375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evaluar modelos (con feature engineering).\n",
    "def evaluate_model_fe(model, set_names=('train_fe', 'validation_fe'), title=''):\n",
    "    if title:\n",
    "        display(title)\n",
    "        \n",
    "    final_metrics = defaultdict(list)\n",
    "   \n",
    "    for i, set_name in enumerate(set_names):\n",
    "        assert set_name in ['train_fe', 'validation_fe', 'test_fe']\n",
    "        set_data = globals()[set_name] \n",
    "\n",
    "        y = set_data.travel_insurance\n",
    "        y_pred = model.predict(set_data)\n",
    "        final_metrics['Accuracy'].append(metrics.accuracy_score(y, y_pred))\n",
    "        final_metrics['Precision'].append(metrics.precision_score(y, y_pred))\n",
    "        \n",
    "    display(pd.DataFrame(final_metrics, index=set_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f6565a",
   "metadata": {},
   "source": [
    "Antes de comenzar con el análisis y evaluación de los modelos, debemos aclarar que los valores de métricas obtenidos, en la mayoría de los casos, difieren en valores decimales, por lo cual los distintos cambios que fuimos aplicando no generan un gran impacto en dichos estimadores, al tratarse de valores pequeños. Sin embargo, decidimos analizar estas pequeñas diferencias para así poder detectar relaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6abe51",
   "metadata": {},
   "source": [
    "##### *Sin feature engeeniring ni alteración de hiperparámetros.*  \n",
    "En primera instancia, evaluamos los 3 modelos elegidos sin haber implementado la feature engineering seleccionada y sin modificar los hiper-parámetros que vienen por defecto. \n",
    "A partir de los valores obtenidos para “Accuracy” en el set de datos de validation, podemos observar que el mejor modelo en este caso sería Gradient Boosting, ya que presenta el mayor valor de ésta métrica en el set de datos de validation con respecto a los demás modelos y con una diferencia casi nula con el resultado obtenido en el set de datos de train. Además, es posible que los demás modelos estén sobreentrenando, especialmente el árbol, ya que la diferencia de la métrica obtenida para el train y para el validation es bastante notoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2029fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN\n",
    "modelKNN = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "modelKNN.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelKNN, title='kNN')\n",
    "\n",
    "# Decision Tree\n",
    "modelTree = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "])\n",
    "modelTree.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelTree, title='Decision Tree')\n",
    "\n",
    "# Gradient Boosting\n",
    "modelGradBoost = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "modelGradBoost.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelGradBoost, title='Gradient Boosting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179ac034",
   "metadata": {},
   "source": [
    "##### *Con feature engeeniring, sin alteración de hiperparámetros.*\n",
    "En segunda instancia, volvimos a evaluar los 3 modelos aún sin modificar los parámetros por defecto, pero esta vez implementando feature engineering, tal como explicamos anteriormente. En este caso, pudimos observar que los valores son prácticamente los mismos que en la instancia anterior, incluso llegando a empeorar el valor del Accuracy. Nuevamente llegamos a la conclusión de que el mejor modelo entre los seleccionados sería el Gradient Boosting. En general, esta técnica de feature engineering, por sí sola, no aporta mejoras a los modelos. Además podemos observar que el árbol continúa sobreentrenando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f4413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN + feature engineering\n",
    "modelKNN_fe = Pipeline([\n",
    "    ('mapper', mapper_fe),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "modelKNN_fe.fit(train_fe, train_fe.travel_insurance)\n",
    "predictions = modelKNN_fe.predict(validation_fe)\n",
    "evaluate_model_fe(modelKNN_fe, title='kNN with feature engineering')\n",
    "\n",
    "# Decision Tree + feature engineering\n",
    "modelTree_fe = Pipeline([\n",
    "    ('mapper', mapper_fe),\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "])\n",
    "modelTree_fe.fit(train_fe, train_fe.travel_insurance)\n",
    "evaluate_model_fe(modelTree_fe, title='Decision Tree with feature engineering')\n",
    "\n",
    "# Gradient Boosting + feature engineering\n",
    "modelGradBoost_fe = Pipeline([\n",
    "    ('mapper', mapper_fe),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "modelGradBoost_fe.fit(train_fe, train_fe.travel_insurance)\n",
    "evaluate_model_fe(modelGradBoost_fe, title='Gradient Boosting with feature engineering')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442dc561",
   "metadata": {},
   "source": [
    "##### *Sin feature engeeniring, alterando hiperparámetros.*\n",
    "En tercera instancia, evaluamos los 3 modelos elegidos sin haber implementado feature engineering, pero modificando los hiper-parámetros que vienen por defecto.   \n",
    "  \n",
    "Con respecto al modelo k-NN, observamos que por defecto venía con un k=5, por lo que decidimos probar con k=3, k=4, k=6, k=7 y k=10. Una vez evaluado cada uno de ellos, pudimos observar que al utilizar un k=4, mejora mínimamente el valor de la métrica en comparación con el k por defecto. Por otra parte, pudimos notar la dependencia e inestabilidad de este modelo en k ya que pequeñas modificaciones en esta, generan valores diversos de la métrica. Con respecto a las k probadas, teniendo en cuenta el valor por defecto de k (5), con k en 4 la métrica mejora, pero también lo hace con 6 y con 10, y por otro lado con 3 y 7 empeora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531fbc46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KNN k=3\n",
    "modelKNN3 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', KNeighborsClassifier(3))\n",
    "])\n",
    "modelKNN3.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelKNN3, title='kNN with k=3')\n",
    "\n",
    "# KNN k=4\n",
    "modelKNN4 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', KNeighborsClassifier(4))\n",
    "])\n",
    "modelKNN4.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelKNN4, title='kNN with k=4')\n",
    "\n",
    "# KNN k=6\n",
    "modelKNN6 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', KNeighborsClassifier(6))\n",
    "])\n",
    "modelKNN6.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelKNN6, title='kNN with k=6')\n",
    "\n",
    "# KNN k=7\n",
    "modelKNN7 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', KNeighborsClassifier(7))\n",
    "])\n",
    "modelKNN7.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelKNN7, title='kNN with k=7')\n",
    "\n",
    "# KNN k=10\n",
    "modelKNN10 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', KNeighborsClassifier(10))\n",
    "])\n",
    "modelKNN10.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelKNN10, title='kNN with k=10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f6ad5",
   "metadata": {},
   "source": [
    "Continuando con el modelo de árbol de decisión, que viene por defecto sin límite de profundidad, le asignamos a éste diferentes valores tales como 4, 8 y 12. Haciendo esto, pudimos comprobar que, tal como dice la teoría, al disminuir la profundidad máxima del árbol se puede llegar a mejores resultados, y se reduce la posibilidad de que dicho modelo sobreentrene. Encontramos como más performante al árbol con una profundidad igual a 4, ya que con ella se obtiene un mejor valor de métrica que con las demás profundidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0648c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree depth=4\n",
    "modelTree4 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', DecisionTreeClassifier(max_depth = 4))\n",
    "])\n",
    "modelTree4.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelTree4, title='Decision Tree with depth=4')\n",
    "\n",
    "# tree depth=8\n",
    "modelTree8 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', DecisionTreeClassifier(max_depth = 8))\n",
    "])\n",
    "modelTree8.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelTree8, title='Decision Tree with depth=8')\n",
    "\n",
    "# tree depth=12\n",
    "modelTree12 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', DecisionTreeClassifier(max_depth = 12))\n",
    "])\n",
    "modelTree12.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelTree12, title='Decision Tree with depth=12')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f83f63",
   "metadata": {},
   "source": [
    "Por último, evaluamos al modelo Gradient Boosting, alterando la cantidad de árboles, la profundidad máxima y el learning rate, primero por separado y después combinándolos.  \n",
    "  \n",
    "En primer lugar probamos el modelo con distintas cantidades de árboles. Sabiendo que el valor por defecto es 100, trabajamos con 10, 50, 100, 150 y 250. A partir de los valores obtenidos podemos concluir que los valores que mejoran en mayor medida la métrica son 10 y 50, mientras que valores mayores a 100 la empeoran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb2e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting n_trees=10\n",
    "modelGradBoost10 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', GradientBoostingClassifier(n_estimators=10, random_state=42))\n",
    "])\n",
    "modelGradBoost10.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelGradBoost10, title='Gradient Boosting with n_trees=10')\n",
    "\n",
    "# gradient boosting n_trees=50\n",
    "modelGradBoost50 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', GradientBoostingClassifier(n_estimators=50, random_state=42))\n",
    "])\n",
    "modelGradBoost50.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelGradBoost50, title='Gradient Boosting with n_trees=50')\n",
    "\n",
    "# gradient boosting n_trees=150\n",
    "modelGradBoost150 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', GradientBoostingClassifier(n_estimators=150, random_state=42))\n",
    "])\n",
    "modelGradBoost150.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelGradBoost150, title='Gradient Boosting with n_trees=150')\n",
    "\n",
    "# gradient boosting n_trees=250\n",
    "modelGradBoost250 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', GradientBoostingClassifier(n_estimators=250, random_state=42))\n",
    "])\n",
    "modelGradBoost250.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelGradBoost250, title='Gradient Boosting with n_trees=250')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf867c66",
   "metadata": {},
   "source": [
    "En segundo lugar probamos el estimador con distintas profundidades para los árboles. Sabiendo que la profundidad por defecto es 3, trabajamos con 4, 6 y 8. A partir de los valores obtenidos, concluimos que la profundidad 3 y 4 son las que mejor funcionan con el modelo. Mientras que, si esta profundidad aumenta, el valor de la métrica empeora, como se puede ver con 6 y 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970704ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting depth=4\n",
    "modelGradBoost4 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', GradientBoostingClassifier(max_depth=4, random_state=42))\n",
    "])\n",
    "modelGradBoost4.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelGradBoost4, title='Gradient Boosting with depth=4')\n",
    "\n",
    "# gradient boosting depth=6\n",
    "modelGradBoost6 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', GradientBoostingClassifier(max_depth=6, random_state=42))\n",
    "])\n",
    "modelGradBoost6.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelGradBoost6, title='Gradient Boosting with depth=6')\n",
    "\n",
    "# gradient boosting depth=8\n",
    "modelGradBoost8 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', GradientBoostingClassifier(max_depth=8, random_state=42))\n",
    "])\n",
    "modelGradBoost8.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelGradBoost8, title='Gradient Boosting with depth=8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7ea37a",
   "metadata": {},
   "source": [
    "En tercer lugar probamos el modelo con distintos valores de learning rate. Sabiendo que el valor por defecto es 0,1, trabajamos con 0,01, 0,05, 0,5, 1 y 2. A partir de ello podemos concluir que los valores menores al valor por defecto mejoran el valor del Accuracy, mientras que los valores mayores al valor por defecto lo empeoran. Incluso, un learning rate de 2 hace que el modelo no pueda converger, ya que, según la teoría, un valor de este muy grande genera una no convergencia y va empeorando con el tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a825e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting lr=0,01\n",
    "modelGradBoost0_01 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', GradientBoostingClassifier(learning_rate=0.01, random_state=42))\n",
    "])\n",
    "modelGradBoost0_01.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelGradBoost0_01, title='Gradient Boosting with learning_rate=0,01')\n",
    "\n",
    "# gradient boosting lr=0,05\n",
    "modelGradBoost0_05 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', GradientBoostingClassifier(learning_rate=0.05, random_state=42))\n",
    "])\n",
    "modelGradBoost0_05.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelGradBoost0_05, title='Gradient Boosting with learning_rate=0,05')\n",
    "\n",
    "# gradient boosting lr=0,5\n",
    "modelGradBoost0_5 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', GradientBoostingClassifier(learning_rate=0.5, random_state=42))\n",
    "])\n",
    "modelGradBoost0_5.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelGradBoost0_5, title='Gradient Boosting with learning_rate=0,5')\n",
    "\n",
    "# gradient boosting lr=1\n",
    "modelGradBoost1 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', GradientBoostingClassifier(learning_rate=1, random_state=42))\n",
    "])\n",
    "modelGradBoost1.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelGradBoost1, title='Gradient Boosting with learning_rate=1')\n",
    "\n",
    "# gradient boosting lr=2\n",
    "modelGradBoost2 = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', GradientBoostingClassifier(learning_rate=2, random_state=42))\n",
    "])\n",
    "modelGradBoost2.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelGradBoost2, title='Gradient Boosting with learning_rate=2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af52736",
   "metadata": {},
   "source": [
    "Finalmente, a partir de los valores anteriores, decidimos combinar estos cambios, probando con aquellos que mejoraban en mayor medida los valores del Accuracy. Entonces, trabajamos con 50 como cantidad de árboles, 3 como profundidad de cada árbol y 0,01 como learning rate. Llegamos a la conclusión de que, estos cambios en conjunto, no mejoran más de lo que lo hacen la cantidad de árboles y el learning rate por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a6cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting n_tree=50, depth=3, lr=0,01\n",
    "modelGradBoostMix = Pipeline([\n",
    "    ('mapper', mapper_scaller),\n",
    "    ('classifier', GradientBoostingClassifier(n_estimators=50, max_depth=3, learning_rate=0.01, random_state=42))\n",
    "])\n",
    "modelGradBoostMix.fit(train, train.travel_insurance)\n",
    "evaluate_model(modelGradBoostMix, title='Gradient Boosting with n_tree=50, depth=3 and lr=0,01')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3f3757",
   "metadata": {},
   "source": [
    "Por otra parte, para estos casos, el estimador Gradient Boosting sigue siendo la mejor opción a partir del valor del Accuracy obtenido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56be49df",
   "metadata": {},
   "source": [
    "##### *Con feature engeeniring, alterando hiperparámetros.*\n",
    "Como última instancia, decidimos combinar la aplicación de feature engineering con la alteración de los hiper-parámetros, de los cuales seleccionamos aquellos que mejor valor de métrica generaban. Entonces trabajamos con un kNN con k=4, con un árbol con profundidad 4 y un Gradient Boosting con 50 árboles y learning rate de 0,01; todos ellos utilizando la técnica de feature engineering seleccionada.  \n",
    "  \n",
    "Con respecto al modelo kNN, al aplicar ambas técnicas pudimos notar una leve mejoría en Accuracy.\n",
    "En cambio, para el árbol de decisión se obtuvieron los mismos valores de la métrica que cuando solo se habían aplicado modificaciones en los hiper-parámetros. Esta misma situación ocurre con Gradient Boosting, ya que al aplicar las dos técnicas juntas no se aumenta el valor de dicha métrica.  \n",
    "  \n",
    "En general, podemos decir, que la modificación de los hiper-parámetros por sí sola, es suficiente para mejorar la performance de los modelos. Esto puede deberse a que la técnica de feature engineering seleccionado no fue óptima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8ed401",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# KNN fe, k=4\n",
    "modelKNN_fe_hp = Pipeline([\n",
    "    ('mapper', mapper_fe),\n",
    "    ('classifier', KNeighborsClassifier(4))\n",
    "])\n",
    "modelKNN_fe_hp.fit(train_fe, train_fe.travel_insurance)\n",
    "predictions = modelKNN_fe.predict(validation_fe)\n",
    "evaluate_model_fe(modelKNN_fe_hp, title='kNN with feature engineering and k=4')\n",
    "\n",
    "# decision tree fe, depth=4\n",
    "modelTree_fe_hp = Pipeline([\n",
    "    ('mapper', mapper_fe),\n",
    "    ('classifier', DecisionTreeClassifier(max_depth=4))\n",
    "])\n",
    "modelTree_fe_hp.fit(train_fe, train_fe.travel_insurance)\n",
    "evaluate_model_fe(modelTree_fe_hp, title='Decision Tree with feature engineering and depth=4')\n",
    "\n",
    "# gradient boosting fe, n_trees=50\n",
    "modelGradBoost_fe_50 = Pipeline([\n",
    "    ('mapper', mapper_fe),\n",
    "    ('classifier', GradientBoostingClassifier(n_estimators=50, random_state=42))\n",
    "])\n",
    "modelGradBoost_fe_50.fit(train_fe, train_fe.travel_insurance)\n",
    "evaluate_model_fe(modelGradBoost_fe_50, title='Gradient Boosting with feature engineering and n_trees=50')\n",
    "\n",
    "# gradient boosting fe, lr=0,01\n",
    "modelGradBoost_fe_0_01 = Pipeline([\n",
    "    ('mapper', mapper_fe),\n",
    "    ('classifier', GradientBoostingClassifier(n_estimators=50, random_state=42))\n",
    "])\n",
    "modelGradBoost_fe_0_01.fit(train_fe, train_fe.travel_insurance)\n",
    "evaluate_model_fe(modelGradBoost_fe_0_01, title='Gradient Boosting with feature engineering and lr=0,01')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daad8e2f",
   "metadata": {},
   "source": [
    "Una vez más, el estimador Gradient Boosting sigue siendo la mejor opción a partir del valor del Accuracy obtenido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9924992a",
   "metadata": {},
   "source": [
    "#### Algunas técnicas para no sobreentrenar\n",
    "* En primer lugar dividimos el dataset en train, test y validation para que los modelos entrenen con un conjunto diferente al que utilizarán para predecir.\n",
    "* También aplicamos modificaciones sobre los hiperparámetros en los diversos modelos, como por ejemplo, establecer una profundidad en el árbol o modificar el learning rate del Gradient Boosting.\n",
    "* Otra opción podría ser la de agregar más ejemplos al dataset, lo cual no pudimos aplicar ya que no disponemos de los mismos. Un ejemplo podría ser el del árbol de decisión sin ninguna modificación. Como podemos ver en el gráfico siguiente, la línea del train y del validation no convergen, por lo que podríamos decir que está sobreentrenando. Sin embargo, a medida que aumenta el tamaño del dataset, estas líneas se van acercando, lo que indica que si agregaríamos más datos, las mismas podrían llegar a converger en algún punto, reduciendo el sobreentrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118626c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gráfico Learning Curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "estimator=modelTree,\n",
    "X=train,\n",
    "y=train.travel_insurance,\n",
    "train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "cv=10,\n",
    "n_jobs=-1,\n",
    "scoring='accuracy')\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color='#0000FF', label='Training')\n",
    "plt.plot(train_sizes, test_mean, color='#FF0000', label='Validation')\n",
    "\n",
    "plt.title('Learning Curve - Decision Tree')\n",
    "plt.xlabel('Tamaño del train')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d11f1",
   "metadata": {},
   "source": [
    "#### Selección de un modelo y valor de la métrica a informar  \n",
    "El modelo seleccionado fue el Gradient Boosting con [un learning rate de 0,01/una cantidad de estimadores igual a 50], ya que es el que mayor valor de Accuracy tuvo en el dataset de validation.  \n",
    "Cabe aclarar que también fuimos controlando que el valor de Precision se mantenga en valores altos, si bien hubo un modelo que obtuvo una mejor Precision (por poco), lo que marcó la decisión fue la primera métrica mencionada, ya que es la que informaremos al cliente. De cualquier forma, obtuvimos buenos valores para ambas métricas, siendo aproximadamente un 0,8463 en Accuracy y un 0,9474 en Precision, para el dataset de validation. Esto quiere decir que el estimador acertó en un 84,63% de las predicciones y en un 94,74% de los ejemplos que predijo como verdaderos (es decir, de los clientes que predijo que iban a comprar el seguro, los que realmente lo hicieron).  \n",
    "Para el caso del Precision, nos interesaría enfocarnos en ese 5,26%, que son aquellos casos que según el estimador iban a comprar, pero no lo hicieron. \n",
    "Sin embargo, como mencionamos antes, la métrica más óptima para informarle al cliente es Accuracy, y este valor se obtiene del dataset de test. Entonces, **el valor a informar es del 84,63%** aproximadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ebcbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(modelGradBoost0_01, title='Gradient Boosting with lr=0,01', set_names=('train', 'validation','test'))\n",
    "evaluate_model(modelGradBoost50, title='Gradient Boosting with n_trees=50', set_names=('train', 'validation','test'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
