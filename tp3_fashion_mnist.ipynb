{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d3e1e18",
   "metadata": {},
   "source": [
    "# Redes Neuronales\n",
    "## Fashion detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencias necesarias\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "# configuración para que las imágenes se vean dentro del notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac4f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos las imágenes (x) y salidas/categorías (y) del dataset\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640f1f67",
   "metadata": {},
   "source": [
    "### 1) Análisis exploratorio sobre el conjunto de datos.  \n",
    "Este es un dataset de 70000 imágenes en blanco y negro de 28x28 pixeles, de 10 categorías de prendas, divididas en un set de train con 60000 imágenes y otro de test de 10000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1974df4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Cantidad y tamaño de imágenes de train:')\n",
    "x_train.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1028139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Cantidad y tamaño de imágenes de test:')\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a6640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clases de prendas\n",
    "CLASES = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \n",
    "          \"Dress\", \"Coat\", \"Sandal\", \"Shirt\",\n",
    "          \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f7b3c2",
   "metadata": {},
   "source": [
    "Ejemplos de la imágenes sin modificaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff30f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(CLASES[y_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a72ae",
   "metadata": {},
   "source": [
    "Las categorías de prendas son las siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc7739",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clase in CLASES:\n",
    "    print(clase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f03758e",
   "metadata": {},
   "source": [
    "A partir de los gráficos siguientes, podemos notar que el set de datos está completamente balanceado tanto en train como test. En el set de train, hay 6000 imágenes de cada tipo de prenda, mientras que en el set de test hay 1000 imágenes de cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e751c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# función para contar y graficar la cantidad de prendas por tipo\n",
    "def distribucion(salidas, titulo=''):\n",
    "    CANTIDADES = [0,0,0,0,0,0,0,0,0,0]\n",
    "    for salida in salidas:\n",
    "        CANTIDADES[salida] += 1\n",
    "        \n",
    "    display(titulo)\n",
    "    plt.pie(CANTIDADES, labels=CLASES, autopct=\"%0.1f %%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6e5356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distribucion(y_train, 'Distribución de train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fb9842",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distribucion(y_test, 'Distribución de test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda8e25c",
   "metadata": {},
   "source": [
    "### 2) Machine Learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9414f1d6",
   "metadata": {},
   "source": [
    "##### Reescalar imágenes  \n",
    "En primera instancia reescalamos los valores de las imágenes, tanto en test como en train. Esto se puede comprobar en los siguientes gráficos que muestran el rango de valores que posee una imagen del dataset antes y después de reescalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4535e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reescalamos los valores de las imágenes\n",
    "x_train_r = x_train/ 255.0\n",
    "x_test_r = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d4b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Antes de escalar:')\n",
    "plt.figure()\n",
    "plt.imshow(x_train[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375a50ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Después de escalar:')\n",
    "plt.figure()\n",
    "plt.imshow(x_train_r[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf273e",
   "metadata": {},
   "source": [
    "##### Modificar el tamaño de las imágenes \n",
    "En cuanto al tamaño de las imágenes, optamos por NO modificarlo, debido a que ya es lo suficientemente pequeño como para entrenar sin demorar demasiado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ff4e1c",
   "metadata": {},
   "source": [
    "#### Funciones para graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7103dbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para graficar la curva de aprendizaje\n",
    "def curva_aprendizaje(historial):\n",
    "    plt.plot(historial.history['accuracy'], label='train')\n",
    "    plt.plot(historial.history['val_accuracy'], label='test')\n",
    "    plt.title('Accuracy over train epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef09c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para graficar la matriz de confusión\n",
    "def matriz_confusion(modelo, dt_x, dt_y, title=''):\n",
    "    predictions = modelo.predict(dt_x)\n",
    "    pred_label = [np.argmax(i) for i in predictions]\n",
    "    labels = dt_y\n",
    "    \n",
    "    conf_matrix = confusion_matrix(labels, pred_label)\n",
    "\n",
    "    ax = sns.heatmap(conf_matrix, \n",
    "                cmap='Blues', \n",
    "                xticklabels=CLASES, \n",
    "                yticklabels=CLASES,\n",
    "                annot=True,\n",
    "                fmt='d')\n",
    "\n",
    "    plt.xlabel('Predicted class') \n",
    "    plt.ylabel('True class') \n",
    "    \n",
    "    print(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414da19f",
   "metadata": {},
   "source": [
    "#### Entrenamiento y evaluación  \n",
    "Para este análisis decidimos definir y evaluar diversas redes neuronales.\n",
    "\n",
    "En un principio definimos una red MLP con determinados parámetros, y en base a ella, probamos otras redes a las cuales les fuimos modificando diversas características como cantidad de capas y de neuronas, cantidad de épocas, tamaño del batch, tipo de función de activación, nivel de dropout, etc. \n",
    "\n",
    "Luego..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f107af",
   "metadata": {},
   "source": [
    "#### REDES NEURONALES 1, 1-a y 1-b\n",
    "La red 1 obtuvo valores de accuracy por encima del 70%, tanto para train como para test, ya en la primera época. Este valor fue aumentando hasta alcanzar un accuracy superior al 90% para train y al 87% para test en la última época.  \n",
    "Además, al observar la curva de aprendizaje, podemos corroborar que no hay sobreentrenamiento, ya que la diferencia del accuracy en train y test, es tan solo del 3% aproximadamente. Sin embargo, a medida que pasan las épocas, estas líneas parecen ir separándose, por lo cual entrenamos una red (1-a) con las mismas características, pero con 80 épocas. Tras analizar la curva de aprendizaje de esta última, comprobamos que el error creció y que la distancia entre las líneas de train y test continúa aumentando, lo cual, si bien sube más los valores del accuracy en test, podría llegar a generar algo de sobreentrenamiento si continuamos agregando épocas.  \n",
    "También decidimos probar a entrenar la red con un batch más pequeño (1-b) y evaluar las medidas obtenidas, pero notamos que no hubo grandes modificaciones en el accuracy. En general, de los 3 casos, hasta ahora, el mejor es el primero, ya que se obtuvo un accuracy mayor en el set de test.  \n",
    "Con respecto a las matrices de confusión, podemos ver que, son bastante similares en los 3 casos. En general, si bien hay muchos aciertos, también hay predicciones erróneas, pero en las clases de prendas que son similares (remera y camisa, botas y zapatillas, por ejemplo), lo cual tiene sentido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2434c2",
   "metadata": {},
   "source": [
    "##### Red Neuronal 1:\n",
    "* Tipo: MLP.\n",
    "* Capas: 3 densas, con 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en la primeras capas y 'softmax' en la de salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de02f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_1 = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0334e457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_mlp_1 = model_mlp_1.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010e2d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d86b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_1, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_1, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525041a8",
   "metadata": {},
   "source": [
    "##### Red Neuronal 1-a:\n",
    "* Tipo: MLP.\n",
    "* Capas: 2 densas, con 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en la primer capa y 'softmax' en la de salida.\n",
    "* **Épocas: 80.**\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c386fa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_1a = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_1a.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_1a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f36529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_1a = model_mlp_1a.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=80,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd616a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c064aaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_1a, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_1a, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6942c784",
   "metadata": {},
   "source": [
    "##### Red Neuronal 1-b:\n",
    "* Tipo: MLP.\n",
    "* Capas: 2 densas, con 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en la primer capa y 'softmax' en la de salida.\n",
    "* Épocas: 25.\n",
    "* **Tamaño del batch: 125.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7eac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_1b = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_1b.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_1b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b8b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_1b = model_mlp_1b.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=125,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513d0055",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_1b, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_1b, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa06c3",
   "metadata": {},
   "source": [
    "#### REDES NEURONALES 2, 2-a y 2-b  \n",
    "Para la red 2, mantuvimos los valores de la red 1, a excepción del número de capas y neuronas, que decidimos aumentar. Tras el entrenamiento, esta obtuvo una diferencia mayor en el accuracy con respecto a la red 1 en ambos sets. Además, podemos ver que el error, para esta red con más parámetros, disminuyó.  \n",
    "Tras modificar la cantidad de épocas en el entrenamiento (red 2-a), también pudimos comprobar que, si bien aumentaba la métrica en train, esta comenzaba a alejarse de los valores de test, confirmando nuevamente que si continuáramos agregando épocas, podría llegar a sobreentrenar.  \n",
    "Por otra parte, decidimos probar una red con mucha más cantidad de capas y neuronas (2-b). Tras entrenarla, comprobamos que tan solo en 10 épocas el accuracy llegaba a valores del 10%, lo cual indica que tener una gran cantidad de parámetros no es bueno, tal y como vimos en la teoría. Esto también se puede comprobar en las matrices de confusión, ya que la red solo predice Shirt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ccde40",
   "metadata": {},
   "source": [
    "##### Red Neuronal 2:\n",
    "* Tipo: MLP.\n",
    "* **Capas: 10 densas, con 60, 60, 60, 60, 40, 40, 40, 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la de salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb05bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_2 = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),   \n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc5d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_2 = model_mlp_2.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c47051",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e409930",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_2, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_2, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f36cf3c",
   "metadata": {},
   "source": [
    "##### Red Neuronal 2-a:\n",
    "* Tipo: MLP.\n",
    "* **Capas: 10 densas, con 60, 60, 60, 60, 40, 40, 40, 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la de salida.\n",
    "* **Épocas: 80.**\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e6888c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_mlp_2a = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),   \n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_2a.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_2a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead43835",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_mlp_2a = model_mlp_2a.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=80,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a046f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ad1d63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_2a, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_2a, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cedcfaa",
   "metadata": {},
   "source": [
    "##### Red Neuronal 2-b:\n",
    "* Tipo: MLP.\n",
    "* **Capas: 31 densas, 3 de 200 neuronas, 7 de 120, 6 de 100, 5 de 80, 4 de 60, 3 de 40, 2 de 20 y la última de 10 neuronas, en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la de salida.\n",
    "* **Épocas: 10.**\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67194021",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_2b = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(200, activation='tanh'),\n",
    "    Dense(200, activation='tanh'),\n",
    "    Dense(200, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(80, activation='tanh'),\n",
    "    Dense(80, activation='tanh'),\n",
    "    Dense(80, activation='tanh'),\n",
    "    Dense(80, activation='tanh'),\n",
    "    Dense(80, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),   \n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_2b.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_2b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3355f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_2b = model_mlp_2b.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a61b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_2b, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_2b, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca47def",
   "metadata": {},
   "source": [
    "#### RED NEURONAL 3:  \n",
    "En esta red, con respecto a la primera, decidimos modificar la función de activación de las capas ocultas, reemplazando ‘tanh’ por ‘relu’, para evaluar si genera alguna diferencia. Tras el entrenamiento comprobamos que este cambio no generó mejores resultados, ya que el accuracy, tanto en train como en test, se redujo. También vimos que aumentó el error.    \n",
    "* Tipo: MLP.\n",
    "* Capas: 3 densas, con 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: no aplica.\n",
    "* **Función de activación: 'relu' en la primeras capas y 'softmax' en la de salida.**\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacd7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_3 = Sequential([\n",
    "    \n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_3.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee13e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_3 = model_mlp_3.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789236ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_3, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_3, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5811ba76",
   "metadata": {},
   "source": [
    "#### RED NEURONAL 4:  \n",
    "Para esta red, mantuvimos los valores de la red 1, a excepción del dropout, ya que decidimos aplicarle un 30% y analizar los resultados. Luego de entrenar, verificamos que esta modificación empeoró los valores del accuracy tanto para train, como para test. También vimos que aumentó el error.  \n",
    "* Tipo: MLP.\n",
    "* Capas: 3 densas, con 20, 20 y 10 neuronas en ese orden.\n",
    "* **Dropout: 30% en capas ocultas.**\n",
    "* Función de activación: 'tanh' en la primeras capas y 'softmax' en la de salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51fd66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_4 = Sequential([\n",
    "    \n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_4.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5388932",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_4 = model_mlp_4.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50ee087",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0fd42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_4, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_4, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af5fcce",
   "metadata": {},
   "source": [
    "MODIFICAR LO SIGUIENTE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a46e77",
   "metadata": {},
   "source": [
    "#### RED NEURONAL 6:\n",
    "* Tipo: Convolucional.\n",
    "* Capas: 2 convolucionales con 8 filtros de 4x4 con stride 1, un max pooling de 4x4 y 4 densas, con 30, 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: 20% en cada capa.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116bdaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_1 = Sequential([\n",
    "    \n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=8, kernel_size=(4, 4), strides=1, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Convolution2D(filters=8, kernel_size=(4, 4), strides=1, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    MaxPooling2D(pool_size=(4, 4)),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(30, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(20, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "            \n",
    "    Dense(20, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b13295",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_1 = model_conv_1.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65436d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9e3f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_1, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_1, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ee7e89",
   "metadata": {},
   "source": [
    "#### RED NEURONAL 7:\n",
    "* Tipo: Convolucional.\n",
    "* Capas: 2 convolucionales con 16 filtros de 4x4 con stride 1, un max pooling de 4x4 y 4 densas, con 30, 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: 20% en cada capa.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6f2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_2 = Sequential([\n",
    "    \n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=16, kernel_size=(4, 4), strides=1, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Convolution2D(filters=16, kernel_size=(4, 4), strides=1, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    MaxPooling2D(pool_size=(4, 4)),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(30, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(20, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "            \n",
    "    Dense(20, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fa93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_2 = model_conv_2.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c3868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39313e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_2, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_2, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b34c1cd",
   "metadata": {},
   "source": [
    "#### RED NEURONAL 8:\n",
    "* Tipo: Convolucional.\n",
    "* Capas: 2 convolucionales con 8 filtros de 8x8 con stride 1, un max pooling de 4x4 y 4 densas, con 30, 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: 20% en cada capa.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeab2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_3 = Sequential([\n",
    "    \n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=8, kernel_size=(8, 8), strides=1, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Convolution2D(filters=8, kernel_size=(8, 8), strides=1, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    MaxPooling2D(pool_size=(4, 4)),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(30, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(20, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "            \n",
    "    Dense(20, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_3.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea4aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_3 = model_conv_3.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f955688",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52df853",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_3, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_3, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9643700",
   "metadata": {},
   "source": [
    "#### RED NEURONAL 9:\n",
    "* Tipo: Convolucional.\n",
    "* Capas: 2 convolucionales con 8 filtros de 4x4 con stride 2, un max pooling de 4x4 y 4 densas, con 30, 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: 20% en cada capa.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f63ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_4 = Sequential([\n",
    "    \n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=8, kernel_size=(8, 8), strides=2, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Convolution2D(filters=8, kernel_size=(4, 4), strides=2, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    MaxPooling2D(pool_size=(4, 4)),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(30, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(20, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "            \n",
    "    Dense(20, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_4.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53689968",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_4 = model_conv_4.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b3eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e821a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_4, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_4, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300f56cc",
   "metadata": {},
   "source": [
    "#### RED NEURONAL 10:\n",
    "* Tipo: Convolucional.\n",
    "* Capas: 4 convolucionales con 8 filtros de 4x4 con stride 1, un max pooling de 4x4 y 4 densas, con 30, 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: 20% en cada capa.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451cb77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_5 = Sequential([\n",
    "    \n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=8, kernel_size=(8, 8), strides=2, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Convolution2D(filters=8, kernel_size=(4, 4), strides=2, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Convolution2D(filters=8, kernel_size=(8, 8), strides=2, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Convolution2D(filters=8, kernel_size=(4, 4), strides=2, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    MaxPooling2D(pool_size=(4, 4)),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(30, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(20, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "            \n",
    "    Dense(20, activation='tanh'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_5.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_5 = model_conv_5.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65aeac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f722c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_5, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_5, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702c640",
   "metadata": {},
   "source": [
    "MODIFICAR LO SIGUIENTE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28be46a4",
   "metadata": {},
   "source": [
    "#### RED NEURONAL 11:\n",
    "* Tipo: Convolucional.\n",
    "* Capas: 2 convolucionales con 8 filtros de 4x4 con stride 1, un max pooling de 4x4 y 4 densas, con 30, 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: 20% en cada capa.\n",
    "* Función de activación: 'relu' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f49d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_6 = Sequential([\n",
    "    \n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=8, kernel_size=(8, 8), strides=2, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Convolution2D(filters=8, kernel_size=(4, 4), strides=2, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    MaxPooling2D(pool_size=(4, 4)),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(30, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(20, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "            \n",
    "    Dense(20, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_6.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1305a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_6 = model_conv_6.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979997d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc05d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_6, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_6, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd7ec22",
   "metadata": {},
   "source": [
    "##### Aumentación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fba929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator_alterado = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    brightness_range=(0.5, 1.5),\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
