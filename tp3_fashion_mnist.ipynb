{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9380a57",
   "metadata": {},
   "source": [
    "# Redes Neuronales\n",
    "## Fashion detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ae5ddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dependencias necesarias\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# configuración para ocultar warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# configuración para no expresar en notación científica\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# configuración para que las imágenes se vean dentro del notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1012529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos las imágenes (x) y salidas/categorías (y) del dataset\n",
    "# divididas en train y test\n",
    "train, test = fashion_mnist.load_data()\n",
    "(x_train, y_train) = train \n",
    "(x_test, y_test) = test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc0060a",
   "metadata": {},
   "source": [
    "### 1) Análisis exploratorio sobre el conjunto de datos.  \n",
    "Este es un dataset de 70000 imágenes en blanco y negro de 28x28 pixeles, de 10 categorías de prendas, divididas en un set de train con 60000 imágenes y otro de test de 10000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5729fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Cantidad y tamaño de imágenes de train:')\n",
    "x_train.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b4417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Cantidad y tamaño de imágenes de test:')\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a19dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clases de prendas\n",
    "CLASES = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \n",
    "          \"Dress\", \"Coat\", \"Sandal\", \"Shirt\",\n",
    "          \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5874cb",
   "metadata": {},
   "source": [
    "Ejemplos de la imágenes sin modificaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabd549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para mostrar imágenes\n",
    "def mostrar_imagenes(entradas, salidas):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(entradas[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(CLASES[salidas[i]])\n",
    "    plt.show()\n",
    "\n",
    "mostrar_imagenes(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce51e07",
   "metadata": {},
   "source": [
    "Las categorías de prendas son las siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a847aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clase in CLASES:\n",
    "    print(clase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3122540",
   "metadata": {},
   "source": [
    "A partir de los gráficos siguientes, podemos notar que el set de datos está completamente balanceado tanto en train como test. En el set de train, hay 6000 imágenes de cada tipo de prenda, mientras que en el set de test hay 1000 imágenes de cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b123b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# función para contar y graficar la cantidad de prendas por tipo\n",
    "def distribucion(salidas, titulo=''):\n",
    "    CANTIDADES = [0,0,0,0,0,0,0,0,0,0]\n",
    "    for salida in salidas:\n",
    "        CANTIDADES[salida] += 1\n",
    "        \n",
    "    display(titulo)\n",
    "    plt.pie(CANTIDADES, labels=CLASES, autopct=\"%0.1f %%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a56254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distribucion(y_train, 'Distribución de train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f7830",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distribucion(y_test, 'Distribución de test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3175cd2f",
   "metadata": {},
   "source": [
    "### 2) Machine Learning.  \n",
    "#### Modificación de las imágenes:  \n",
    "##### - Modificar el tamaño \n",
    "En cuanto al tamaño de las imágenes, optamos por NO modificarlo, debido a que ya es lo suficientemente pequeño como para entrenar sin demorar demasiado.  \n",
    "###### - Reescalar valores\n",
    "Decidimos reescalar los valores de las imágenes entre 0 y 1, tanto en test como en train, ya que es necesario para que las redes funcionen correctamente. Esto se puede comprobar en los siguientes gráficos que muestran el rango de valores que posee una imagen del dataset antes y después de reescalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f6207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reescalamos los valores de las imágenes\n",
    "x_train_r = x_train / 255.0\n",
    "x_test_r = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cea6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Antes de reescalar')\n",
    "plt.imshow(x_train[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1452524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Después de escalar')\n",
    "plt.imshow(x_train_r[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080be536",
   "metadata": {},
   "source": [
    "*Algunas funciones para graficar:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a5b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para graficar la curva de aprendizaje\n",
    "def curva_aprendizaje(historial):\n",
    "    plt.plot(historial.history['accuracy'], label='train')\n",
    "    plt.plot(historial.history['val_accuracy'], label='test')\n",
    "    plt.title('Accuracy over train epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f929ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para graficar la matriz de confusión\n",
    "def matriz_confusion(modelo, dt_x, dt_y, title=''):\n",
    "    predictions = modelo.predict(dt_x)\n",
    "    pred_label = [np.argmax(i) for i in predictions]\n",
    "    labels = dt_y\n",
    "    \n",
    "    conf_matrix = confusion_matrix(labels, pred_label)\n",
    "\n",
    "    ax = sns.heatmap(conf_matrix, \n",
    "                cmap='Blues', \n",
    "                xticklabels=CLASES, \n",
    "                yticklabels=CLASES,\n",
    "                annot=True,\n",
    "                fmt='d')\n",
    "\n",
    "    plt.xlabel('Predicted class') \n",
    "    plt.ylabel('True class') \n",
    "    \n",
    "    print(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c2a51e",
   "metadata": {},
   "source": [
    "#### ENTRENAMIENTO Y EVALUACIÓN DE MODELOS:  \n",
    "Para este análisis decidimos definir y evaluar diversas redes neuronales.\n",
    "\n",
    "En un principio definimos una red MLP con determinados parámetros, y en base a ella, probamos otras redes a las cuales les fuimos modificando diversas características como cantidad de capas y de neuronas, cantidad de épocas, tamaño del batch, tipo de función de activación, nivel de dropout, etc. \n",
    "\n",
    "Luego a la primer red MLP le agregamos una capa convolucional con ciertas características y así poder probar diversas redes de tipo convolucional, cambiando cantidad de filtros, tamañano del kernel, strides, cantidad de capas convolucionales, padding, entre otras cosas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700a422b",
   "metadata": {},
   "source": [
    "##### Redes Neuronales 1, 1-a y 1-b:\n",
    "La red 1 obtuvo valores de accuracy por encima del 70%, tanto para train como para test, ya en la primera época. Este valor fue aumentando hasta alcanzar un accuracy superior al 90% para train y al 87% para test en la última época.  \n",
    "Además, al observar la curva de aprendizaje, podemos corroborar que no hay sobreentrenamiento, ya que la diferencia del accuracy en train y test, es tan solo del 3% aproximadamente. Sin embargo, a medida que pasan las épocas, estas líneas parecen ir separándose, por lo cual entrenamos una red (1-a) con las mismas características, pero con 80 épocas. Tras analizar la curva de aprendizaje de esta última, comprobamos que el error creció y que la distancia entre las líneas de train y test continúa aumentando, lo cual, si bien sube más los valores del accuracy en test, podría llegar a generar algo de sobreentrenamiento si continuamos agregando épocas.  \n",
    "También decidimos probar a entrenar la red con un batch más pequeño (1-b) y evaluar las medidas obtenidas, pero notamos que no hubo grandes modificaciones en el accuracy. En general, de los 3 casos, hasta ahora, el mejor es el primero, ya que se obtuvo un accuracy mayor en el set de test.  \n",
    "Con respecto a las matrices de confusión, podemos ver que, son bastante similares en los 3 casos. En general, si bien hay muchos aciertos, también hay predicciones erróneas, pero en las clases de prendas que son similares (remera y camisa, botas y zapatillas, por ejemplo), lo cual tiene sentido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03afe26",
   "metadata": {},
   "source": [
    "##### - Red Neuronal 1\n",
    "* Tipo: MLP.\n",
    "* Capas: 3 densas, con 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en la primeras capas y 'softmax' en la de salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_1 = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307b514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_mlp_1 = model_mlp_1.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4be90a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e974a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_1, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_1, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad236f31",
   "metadata": {},
   "source": [
    "##### - Red Neuronal 1-a\n",
    "* Tipo: MLP.\n",
    "* Capas: 2 densas, con 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en la primer capa y 'softmax' en la de salida.\n",
    "* **Épocas: 80.**\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778a52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_1a = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_1a.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_1a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62288b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_1a = model_mlp_1a.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=80,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27140548",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0357148f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_1a, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_1a, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091613f3",
   "metadata": {},
   "source": [
    "##### - Red Neuronal 1-b\n",
    "* Tipo: MLP.\n",
    "* Capas: 2 densas, con 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en la primer capa y 'softmax' en la de salida.\n",
    "* Épocas: 25.\n",
    "* **Tamaño del batch: 125.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437b9abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_1b = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_1b.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_1b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80548d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_1b = model_mlp_1b.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=125,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd6708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e785963",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_1b, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_1b, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691f16d0",
   "metadata": {},
   "source": [
    "##### Redes Neuronales 2, 2-a y 2-b:\n",
    "Para la red 2, mantuvimos los valores de la red 1, a excepción del número de capas y neuronas, que decidimos aumentar. Tras el entrenamiento, esta obtuvo una diferencia mayor en el accuracy con respecto a la red 1 en ambos sets. Además, podemos ver que el error, para esta red con más parámetros, disminuyó.  \n",
    "Tras modificar la cantidad de épocas en el entrenamiento (red 2-a), también pudimos comprobar que, si bien aumentaba la métrica en train, esta comenzaba a alejarse de los valores de test, confirmando nuevamente que si continuáramos agregando épocas, podría llegar a sobreentrenar.  \n",
    "Por otra parte, decidimos probar una red con mucha más cantidad de capas y neuronas (2-b). Tras entrenarla, comprobamos que tan solo en 10 épocas el accuracy llegaba a valores del 10%, lo cual indica que tener una gran cantidad de parámetros no es bueno, tal y como vimos en la teoría. Esto también se puede comprobar en las matrices de confusión, ya que la red solo predice Shirt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707ac4e6",
   "metadata": {},
   "source": [
    "##### - Red Neuronal 2  \n",
    "* Tipo: MLP.\n",
    "* **Capas: 10 densas, con 60, 60, 60, 60, 40, 40, 40, 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la de salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7404136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_2 = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),   \n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d1fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_2 = model_mlp_2.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b287578",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa3cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_2, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_2, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f32b7",
   "metadata": {},
   "source": [
    "##### - Red Neuronal 2-a  \n",
    "* Tipo: MLP.\n",
    "* **Capas: 10 densas, con 60, 60, 60, 60, 40, 40, 40, 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la de salida.\n",
    "* **Épocas: 80.**\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296e783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_mlp_2a = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),   \n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_2a.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_2a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b5bd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_mlp_2a = model_mlp_2a.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=80,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d10987",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27079c4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_2a, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_2a, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed167a",
   "metadata": {},
   "source": [
    "##### - Red Neuronal 2-b  \n",
    "* Tipo: MLP.\n",
    "* **Capas: 31 densas, 3 de 200 neuronas, 7 de 120, 6 de 100, 5 de 80, 4 de 60, 3 de 40, 2 de 20 y la última de 10 neuronas, en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la de salida.\n",
    "* **Épocas: 10.**\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f5f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_2b = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(200, activation='tanh'),\n",
    "    Dense(200, activation='tanh'),\n",
    "    Dense(200, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(80, activation='tanh'),\n",
    "    Dense(80, activation='tanh'),\n",
    "    Dense(80, activation='tanh'),\n",
    "    Dense(80, activation='tanh'),\n",
    "    Dense(80, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),   \n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_2b.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_2b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83a7ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_2b = model_mlp_2b.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10127b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b43ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_2b, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_2b, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eddef3",
   "metadata": {},
   "source": [
    "##### Red Neuronal 3:  \n",
    "En esta red, con respecto a la primera, decidimos modificar la función de activación de las capas ocultas, reemplazando ‘tanh’ por ‘relu’, para evaluar si genera alguna diferencia. Tras el entrenamiento comprobamos que este cambio no generó mejores resultados, ya que el accuracy, tanto en train como en test, se redujo. También vimos que aumentó el error.    \n",
    "* Tipo: MLP.\n",
    "* Capas: 3 densas, con 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: no aplica.\n",
    "* **Función de activación: 'relu' en la primeras capas y 'softmax' en la de salida.**\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_3 = Sequential([\n",
    "    \n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_3.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed56eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_3 = model_mlp_3.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2555398",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a680b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_3, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_3, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466466c5",
   "metadata": {},
   "source": [
    "##### Red Neuronal 4:  \n",
    "Para esta red, mantuvimos los valores de la red 1, a excepción del dropout, ya que decidimos aplicarle un 30% y analizar los resultados. Luego de entrenar, verificamos que esta modificación empeoró los valores del accuracy tanto para train, como para test. También vimos que aumentó el error.  \n",
    "* Tipo: MLP.\n",
    "* Capas: 3 densas, con 20, 20 y 10 neuronas en ese orden.\n",
    "* **Dropout: 30% en capas ocultas.**\n",
    "* Función de activación: 'tanh' en la primeras capas y 'softmax' en la de salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e6e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_4 = Sequential([\n",
    "    \n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_4.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14351648",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_4 = model_mlp_4.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f195032",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc001b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_4, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_4, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f8d515",
   "metadata": {},
   "source": [
    "##### Red Neuronal 5:  \n",
    "Esta red presenta las mismas características que la red 1, pero con la diferencia de que ahora incluye una capa convolucional de 4 filtros de 2x2 y stride 1. Esto hizo que el accuracy sea el mayor hasta ahora, con respecto a las demás redes analizadas, es decir que mejora el valor de la métrica. Además, también hizo que se redujera el error con respecto a dichas redes.  \n",
    "* **Tipo: Convolucional.**\n",
    "* **Capas: 1 convolucional con 4 filtros de 2x2 y stride 1, un max pooling de 2x2 y 3 densas, con 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a464a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_1 = Sequential([\n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=4, kernel_size=(2, 2), strides=1, activation='tanh'), \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13563ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_1 = model_conv_1.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29542dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_1, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_1, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa60b18b",
   "metadata": {},
   "source": [
    "##### Red Neuronal 6:    \n",
    "Basándonos en la red 5, decidimos probar una red que modifique la cantidad de filtros de la capa de convolución, que ahora pasará de 4 a 8. Este cambió generó un aumento del accuracy con  respecto a la capa anterior, por lo cual consideramos que tener más filtros, en este caso, podría llegar a ser una mejor opción. Además, también hizo que se redujera considerablemente el error, inclusive más que la red anterior.  \n",
    "* Tipo: Convolucional.\n",
    "* **Capas: 1 convolucional con 8 filtros de 2x2 y stride 1, un max pooling de 2x2 y 3 densas, con 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8e4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_2 = Sequential([    \n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=8, kernel_size=(2, 2), strides=1, activation='tanh'), \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc96461",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_2 = model_conv_2.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc4323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0f5b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_2, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_2, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91908e26",
   "metadata": {},
   "source": [
    "##### Red Neuronal 7: \n",
    "Basándonos en la red 5, también decidimos probar una red que modifique el tamaño de los filtros de la capa de convolución, que ahora pasará de 4x4 a 8x8. Este cambió bajó, en muy pequeña medida, el valor del accuracy con respecto a las anteriores, por lo que podríamos decir que esta modificación, no aporta grandes mejoras. También podemos mencionar que, si bien, reduce un poco el error, este valor no es significativo respecto al error de las demás redes.  \n",
    "* Tipo: Convolucional.\n",
    "* **Capas: 1 convolucional con 4 filtros de 8x8 y stride 1, un max pooling de 2x2 y 3 densas, con 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20070dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_3 = Sequential([\n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=4, kernel_size=(8, 8), strides=1, activation='tanh'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_3.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9931b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_conv_3 = model_conv_3.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce995f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af5c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_3, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_3, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935b6e5c",
   "metadata": {},
   "source": [
    "##### Red Neuronal 8:  \n",
    "A partir de la red 5, también decidimos probar una red que modifique el stride de la capa de convolución, que ahora pasará de 1 a 2. Este cambió no aportó una mejora significativa con respecto al accuracy de las redes anteriores, ya que puntualmente, presenta casi el mismo valor que la red 1. También podemos mencionar que, si bien, reduce un poco el error, este valor no es significativo respecto al error de las demás redes.  \n",
    "* Tipo: Convolucional.\n",
    "* **Capas: 1 convolucional con 4 filtros de 2x2 y stride 2, un max pooling de 2x2 y 3 densas, con 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_4 = Sequential([\n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=4, kernel_size=(2, 2), strides=2, activation='tanh'), \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_4.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd0ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_4 = model_conv_4.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c904c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e1b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_4, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_4, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2107cf8d",
   "metadata": {},
   "source": [
    "##### Red Neuronal 9:  \n",
    "Basándonos en la red 5, también decidimos probar una red que rellene la entrada con 0, es decir, utilizar padding. Este cambió mejoró, en muy pequeña medida, el valor del accuracy con respecto a la red 1 pero no con respecto a todas las anteriores, por lo que podríamos decir que esta modificación, no aporta grandes mejoras. También podemos mencionar que reduce considerablemente el error, con respecto al de las demás redes, pero no más que la red 6.  \n",
    "* Tipo: Convolucional.\n",
    "* **Capas: 1 convolucional con 4 filtros de 2x2, stride 1 y padding, un max pooling de 2x2 y 3 densas, con 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df363f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_5 = Sequential([\n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=4, kernel_size=(2, 2), strides=1, padding='same', activation='tanh'), \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_5.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c264b54e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_conv_5 = model_conv_5.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5aa83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf1da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_5, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_5, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f099a5b4",
   "metadata": {},
   "source": [
    "##### Red Neuronal 10:  \n",
    "Quizás trabajar con una sola capa convolucional es poco, así que decidimos probar una red que agregue más de una capa de convolución. Ahora trabajaremos con 3 capas en lugar de 1. Estas tendrán las mismas características que la red 5. Tras el entrenamiento podemos ver que este cambio aportó una suba en el valor de la métrica con respecto a dicha red 5, por lo cual es un factor a tener en cuenta a la hora de “mejorar” una red. Además, también hizo que se redujera considerablemente el error, casi al nivel de la red 6.  \n",
    "* Tipo: Convolucional.\n",
    "* **Capas: 3 convolucionales con 4 filtros de 2x2 y stride 1, un max pooling de 2x2 y 3 densas, con 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76447a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_6 = Sequential([\n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=4, kernel_size=(2, 2), strides=1, activation='tanh'),\n",
    "    Convolution2D(filters=4, kernel_size=(2, 2), strides=1, activation='tanh'), \n",
    "    Convolution2D(filters=4, kernel_size=(2, 2), strides=1, activation='tanh'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_6.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0438622",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_6 = model_conv_6.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e4ae5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14676674",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_6, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_6, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e1e835",
   "metadata": {},
   "source": [
    "##### Red Neuronal 11:  \n",
    "Para esta red, decidimos aplicar aquellos cambios que consideramos que, por los análisis anteriores, mejoraban en mayor medida, los valores del accuracy y del error, como por ejemplo, agregar más capas y aumentar la cantidad de filtros por capa. Estos cambios, confirmaron que aplicarlos, genera mejores resultados, ya que de todas las redes probadas, es la que mayor valor de accuracy obtuvo. Aunque cabe aclarar que no es una diferencia tan grande, sobre todo con respecto a la red 6. También podemos mencionar que redujo considerablemente el error, pero no más que dicha red 6. Podemos decir que con solo agregar más filtros podría ser suficiente para obtener buenos valores. Con respecto a la curva de aprendizaje, podemos ver que a medida que avanzan las épocas, las líneas de train y test se separan cada vez más, por lo cual si agregaríamos más épocas, el modelo podría llegar a sobreentrenar.  \n",
    "* Tipo: Convolucional.\n",
    "* **Capas: 4 convolucionales, 1 con 16 filtros y 3 con 8 filtros de 2x2 y stride 1, un max pooling de 2x2 y 3 densas, con 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f4751",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_7 = Sequential([\n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=16, kernel_size=(2, 2), strides=1, activation='tanh'),\n",
    "    Convolution2D(filters=8, kernel_size=(2, 2), strides=1, activation='tanh'), \n",
    "    Convolution2D(filters=8, kernel_size=(2, 2), strides=1, activation='tanh'),\n",
    "    Convolution2D(filters=8, kernel_size=(2, 2), strides=1, activation='tanh'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_7.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aef45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_7 = model_conv_7.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1590445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad555aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_7, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_7, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75527db3",
   "metadata": {},
   "source": [
    "#### AUMENTACIÓN DE DATOS:\n",
    "Para probar esta técnica elegimos el modelo que mayor valor de accuracy obtuvo en train, es decir, la red 11, que agregaba más capas convolucionales y más filtros. Por otra parte, también decidimos aplicarlo en la primer red creada, es decir la 1, para verificar si generaba mejoras.  \n",
    "Para modificar las imágenes, alteramos parámetros como el ángulo de rotación, nivel de desplazamiento horizontal y vertical, brillo, espejar horizontalmente la imagen, y nivel de aumento.  \n",
    "Una vez hecho esto, agregamos dichas imágenes al dataset original para generar el aumento de datos. Ahora pasaríamos de entrenar con 60000 imágenes a entrenar con 120000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c84f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos un dataset de train con imagénes alteradas\n",
    "# se obtiene en formato de tensor\n",
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=(0.5, 1.5),\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    zoom_range=0.1,\n",
    ")\n",
    "\n",
    "train_alterado = data_generator.flow(\n",
    "    x_train_r.reshape(60000,28,28,1),\n",
    "    y_train,\n",
    "    batch_size = 60000,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b82a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizamos el mismo generador (pero sin modificaciones)\n",
    "# para obtener el dataset en formato de tensor\n",
    "data_no_generator = ImageDataGenerator()\n",
    "\n",
    "train_no_alterado = data_no_generator.flow(\n",
    "    x_train_r.reshape(60000,28,28,1),\n",
    "    y_train,\n",
    "    batch_size = 60000,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10d32e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separamos los tensores en imágenes y etiquetas\n",
    "imagenes_a, etiquetas_a = train_alterado.next()\n",
    "imagenes_n, etiquetas_n = train_no_alterado.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62f7293",
   "metadata": {},
   "source": [
    "Podemos ver algunos ejemplos de las imágenes modificadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c13b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_imagenes(imagenes_a, etiquetas_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b3712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenamos las imágenes originales con las modificadas\n",
    "train_ampliado_imagenes = np.concatenate((\n",
    "    imagenes_n,\n",
    "    imagenes_a\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b522ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenamos los labels de las imágenes originales con los\n",
    "# de las imágenes modificadas\n",
    "train_ampliado_etiquetas = np.concatenate((\n",
    "    etiquetas_n,\n",
    "    etiquetas_a\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec6272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos una red con las mismas características que la nro. 11\n",
    "model_conv_8 = Sequential([\n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=16, kernel_size=(2, 2), strides=1, activation='tanh'),\n",
    "    Convolution2D(filters=8, kernel_size=(2, 2), strides=1, activation='tanh'), \n",
    "    Convolution2D(filters=8, kernel_size=(2, 2), strides=1, activation='tanh'),\n",
    "    Convolution2D(filters=8, kernel_size=(2, 2), strides=1, activation='tanh'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_8.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6856ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_8 = model_conv_8.fit(\n",
    "    train_ampliado_imagenes,\n",
    "    train_ampliado_etiquetas,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea45db",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b534b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos una red con las mismas características que la nro. 1\n",
    "model_mlp_12 = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_12.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_12.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea9327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_12 = model_mlp_12.fit(\n",
    "    train_ampliado_imagenes,\n",
    "    train_ampliado_etiquetas,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2da95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2410eadc",
   "metadata": {},
   "source": [
    "Tras entrenar ambos modelos con el dataset aumentado, pudimos comprobar que, en este caso, la técnica no aportó mejoras, ya que el valor del accuracy obtenido en ambos modelos, fue mayor cuando se entrenó con el dataset original. Incluso el nivel de error se mantuvo más alto en los modelos con los dataset aumentados.    \n",
    "Podemos suponer que esto se debe a que quizás las alteraciones sobre las imágenes fueron un tanto excesivas o no las adecuadas para estas imágenes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e231db6d",
   "metadata": {},
   "source": [
    "#### TRANFER LEARNING - VGG16:     \n",
    "Uno de los modelos de alto rendimiento para el reconocimiento de imágenes que se pueden descargar y utilizar como base para el reconocimiento de imágenes es el VGG16. Este es el modelo que decidimos usar para aplicar la transferencia de aprendizaje.  \n",
    "VGG16 contiene varios bloques de capas de convolución de filtros de 3x3 con stride de 1 y max pooling de 2x2 con stride 2. Al final, tiene 2 capas densas, seguidas de softmax para la salida. El 16 en VGG16 se refiere a que tiene 16 capas que tienen pesos.   \n",
    "El modelo logra una precisión de prueba del 92,7% entre los 5 primeros datasets en ImageNet (conjuntos de datos de más de 14 millones de imágenes pertenecientes a 1000 clases).   \n",
    "Para utilizar este modelo, reemplazamos las capas densas y de salida del mismo, por otras capas que nos servirán para predecir las imágenes de nuestro dataset. Manteniendo el peso de las capas convolucionales, entrenamos las capas agregadas con las imágenes de train, previamente alteradas para adaptarse a VGG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690fef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizamos el generador utilizado anteriormente (sin cambios)\n",
    "# para obtener el dataset de test en formato de tensor\n",
    "test_no_alterado = data_no_generator.flow(\n",
    "    x_test_r.reshape(10000,28,28,1),\n",
    "    y_test,\n",
    "    batch_size = 10000,\n",
    "    shuffle=False)\n",
    "\n",
    "# separamos el tensor en imágenes y etiquetas\n",
    "imagenes_n_t, etiquetas_n_t = test_no_alterado.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ad5aec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# modificamos las imágenes para que tengan 3 canales (rgb)\n",
    "# de manera que sean toleradas por VGG16\n",
    "x_train_color = tf.image.grayscale_to_rgb(tf.convert_to_tensor(imagenes_n))\n",
    "x_test_color = tf.image.grayscale_to_rgb(tf.convert_to_tensor(imagenes_n_t))\n",
    "\n",
    "# modificamos el tamaño de las imágenes al mínimo tolerado por VGG16\n",
    "x_train_color = tf.image.resize(x_train_color, [32,32])\n",
    "x_test_color = tf.image.resize(x_test_color, [32,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f705a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nuevo formato de las imágenes:')\n",
    "x_train_color[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67de13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre procesamos las imágenes para que sean utilizadas por VGG16\n",
    "train_i = preprocess_input(x_train_color) \n",
    "test_i = preprocess_input(x_test_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ebe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# descargamos VGG16 con sus pesos correspondientes\n",
    "# descartando las capas densas\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(32,32,3))\n",
    "\n",
    "# frizzamos las capas convolucionales para preservar\n",
    "# los pesos durante el entrenamiento\n",
    "base_model.trainable = False\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d06d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos un modelo que tome como base el VGG16 descargado\n",
    "# adicionando nuevas capas densas\n",
    "model_tl = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax')\n",
    "])\n",
    "\n",
    "model_tl.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_tl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df028aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_tl = model_tl.fit(\n",
    "    x_train_color,\n",
    "    etiquetas_n,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_color, etiquetas_n_t)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c8d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e049db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_tl, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_tl, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0345e3",
   "metadata": {},
   "source": [
    "Tras el entrenamiento comprobamos que el modelo obtuvo un accuracy en el set de test bastante bueno, pero no superior a los modelos trabajados anteriormente. Creemos que un factor que podría influenciar su aprovechamiento es que VGG trabaja con imágenes a color, mientras que nuestro dataset está en escala de grises. Si bien hicimos las transformaciones necesarias para que respete este formato, algunos filtros que pudiesen haber sacado información relacionada a los colores podrían no estarse aprovechando."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4251408",
   "metadata": {},
   "source": [
    "### 3) Conclusiones.   \n",
    "AGREGAR CONCLUSIÓN GENERAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da1479a",
   "metadata": {},
   "source": [
    "#### Desempeño del modelo por clase:  \n",
    "Para evaluar el desempeño de un modelo por clase, elegimos la red 11, es decir, la misma que utilizamos para hacer aumentación de datos, ya que era la que mayor valor de accuracy obtenía.  \n",
    "A partir de la matriz de confusión del modelo, podemos ver que este tiene un muy buen desempeño, mantiendo la mayoría de las predicciones en la categoría correcta, exceptuando casos en los que se confunde prendas que son bastante similares como: T-shirt/top y Shirt, Pullover y Coat, Coat y Shirt, entre otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1c6436",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_7, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dfe774",
   "metadata": {},
   "source": [
    "#### Aciertos y desaciertos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088013fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos las predicciones de test de la red 11 \n",
    "predictions = model_conv_7.predict(x_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56382156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones para graficar los ejemplos y\n",
    "# mostrar los mayores porcentajes de confianza de las clases\n",
    "# diferenciando la acertada de las que no\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(CLASES[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                CLASES[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array, true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bbf1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para mostrar casos de aciertos y desaciertos\n",
    "def mostrar_aciertos_desaciertos(clase, acierto):\n",
    "    count = 0\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        if(acierto==1):\n",
    "            if(CLASES[np.argmax(prediction)]==CLASES[y_test[i]]):\n",
    "                if(clase==CLASES[np.argmax(prediction)]):\n",
    "                    count+=1            \n",
    "                    plt.figure(figsize=(4,2))\n",
    "                    plt.subplot(1,2,1)\n",
    "                    plot_image(i, prediction, y_test, x_test_r)\n",
    "                    plt.subplot(1,2,2)\n",
    "                    plot_value_array(i, prediction,  y_test)\n",
    "                    plt.show()\n",
    "        else:\n",
    "            if(CLASES[np.argmax(prediction)]!=CLASES[y_test[i]]):\n",
    "                if(clase==CLASES[y_test[i]]):\n",
    "                    count+=1            \n",
    "                    plt.figure(figsize=(4,2))\n",
    "                    plt.subplot(1,2,1)\n",
    "                    plot_image(i, prediction, y_test, x_test_r)\n",
    "                    plt.subplot(1,2,2)\n",
    "                    plot_value_array(i, prediction,  y_test)\n",
    "                    plt.show()\n",
    "        if(count==2):\n",
    "            break           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8b9eee",
   "metadata": {},
   "source": [
    "###### T-shirt/top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df16b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('T-shirt/top', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('T-shirt/top', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ca70ad",
   "metadata": {},
   "source": [
    "###### Trouser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9997c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Trouser', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598fdcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Trouser', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b51cc",
   "metadata": {},
   "source": [
    "###### Pullover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf2bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Pullover', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1262a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Pullover', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45e19a2",
   "metadata": {},
   "source": [
    "###### Dress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9a4dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Dress', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e116dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Dress', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618b38c4",
   "metadata": {},
   "source": [
    "###### Coat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30526945",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Coat', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd35b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Coat', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50af403",
   "metadata": {},
   "source": [
    "###### Sandal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Sandal', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffdd00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Sandal', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964e75eb",
   "metadata": {},
   "source": [
    "###### Shirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b21225",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Shirt', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e11c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Shirt', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd10b47b",
   "metadata": {},
   "source": [
    "###### Sneaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa751f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Sneaker', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccaa968",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Sneaker', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087bee35",
   "metadata": {},
   "source": [
    "###### Bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7bfc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Bag', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f073695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Bag', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c92454",
   "metadata": {},
   "source": [
    "###### Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f4425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Ankle boot', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d977cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Ankle boot', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62c6e23",
   "metadata": {},
   "source": [
    "#### Casos reales:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2ca816",
   "metadata": {},
   "source": [
    "Decidimos probar dicha red 11 con otras imágenes de prendas, fuera del dataset. Como podemos ver las predicciones no fueron muy buenas, ya que de 4 casos, solo acertó un caso y con una probabilidad baja.  \n",
    "Esto puede indicarnos que el modelo funciona bien solo con las imágenes del dataset, es decir que de alguna manera, está sobreentrenando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43994b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para mostrar una imagen de ropa y predecir su tipo\n",
    "def mostrar_predecir(image_path):\n",
    "    image_array = img_to_array(load_img(image_path, grayscale=True, target_size=(28, 28)))\n",
    "    inputs = np.array([image_array])\n",
    "    predictions = model_conv_7.predict(inputs)\n",
    "    display(Image(image_path, width=150))\n",
    "    print(\"Prediction:\", CLASES[np.argmax(predictions)])\n",
    "    print(\"Prediction detail:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58bd60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mostrar_predecir(\"./ropa/Shirt.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a0d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_predecir(\"./ropa/Ankle_boot.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ecf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_predecir(\"./ropa/Bag.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74219046",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_predecir(\"./ropa/Trouser.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
