{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9380a57",
   "metadata": {},
   "source": [
    "# Redes Neuronales\n",
    "## Fashion detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ae5ddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dependencias necesarias\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# configuración para que las imágenes se vean dentro del notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1012529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenemos las imágenes (x) y salidas/categorías (y) del dataset\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc0060a",
   "metadata": {},
   "source": [
    "### 1) Análisis exploratorio sobre el conjunto de datos.  \n",
    "Este es un dataset de 70000 imágenes en blanco y negro de 28x28 pixeles, de 10 categorías de prendas, divididas en un set de train con 60000 imágenes y otro de test de 10000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5729fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Cantidad y tamaño de imágenes de train:')\n",
    "x_train.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b4417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Cantidad y tamaño de imágenes de test:')\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a19dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clases de prendas\n",
    "CLASES = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \n",
    "          \"Dress\", \"Coat\", \"Sandal\", \"Shirt\",\n",
    "          \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5874cb",
   "metadata": {},
   "source": [
    "Ejemplos de la imágenes sin modificaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabd549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para mostrar imágenes\n",
    "def mostrar_imagenes(entradas, salidas):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(entradas[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(CLASES[salidas[i]])\n",
    "    plt.show()\n",
    "\n",
    "mostrar_imagenes(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce51e07",
   "metadata": {},
   "source": [
    "Las categorías de prendas son las siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a847aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clase in CLASES:\n",
    "    print(clase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3122540",
   "metadata": {},
   "source": [
    "A partir de los gráficos siguientes, podemos notar que el set de datos está completamente balanceado tanto en train como test. En el set de train, hay 6000 imágenes de cada tipo de prenda, mientras que en el set de test hay 1000 imágenes de cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b123b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# función para contar y graficar la cantidad de prendas por tipo\n",
    "def distribucion(salidas, titulo=''):\n",
    "    CANTIDADES = [0,0,0,0,0,0,0,0,0,0]\n",
    "    for salida in salidas:\n",
    "        CANTIDADES[salida] += 1\n",
    "        \n",
    "    display(titulo)\n",
    "    plt.pie(CANTIDADES, labels=CLASES, autopct=\"%0.1f %%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a56254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distribucion(y_train, 'Distribución de train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f7830",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distribucion(y_test, 'Distribución de test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3175cd2f",
   "metadata": {},
   "source": [
    "### 2) Machine Learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb85d50",
   "metadata": {},
   "source": [
    "##### Reescalar imágenes  \n",
    "En primera instancia reescalamos los valores de las imágenes, tanto en test como en train. Esto se puede comprobar en los siguientes gráficos que muestran el rango de valores que posee una imagen del dataset antes y después de reescalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f6207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reescalamos los valores de las imágenes\n",
    "x_train_r = x_train/ 255.0\n",
    "x_test_r = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cea6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Antes de escalar:')\n",
    "plt.figure()\n",
    "plt.imshow(x_train[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1452524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Después de escalar:')\n",
    "plt.figure()\n",
    "plt.imshow(x_train_r[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba33119",
   "metadata": {},
   "source": [
    "##### Modificar el tamaño de las imágenes \n",
    "En cuanto al tamaño de las imágenes, optamos por NO modificarlo, debido a que ya es lo suficientemente pequeño como para entrenar sin demorar demasiado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080be536",
   "metadata": {},
   "source": [
    "#### Funciones para graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a5b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para graficar la curva de aprendizaje\n",
    "def curva_aprendizaje(historial):\n",
    "    plt.plot(historial.history['accuracy'], label='train')\n",
    "    plt.plot(historial.history['val_accuracy'], label='test')\n",
    "    plt.title('Accuracy over train epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f929ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para graficar la matriz de confusión\n",
    "def matriz_confusion(modelo, dt_x, dt_y, title=''):\n",
    "    predictions = modelo.predict(dt_x)\n",
    "    pred_label = [np.argmax(i) for i in predictions]\n",
    "    labels = dt_y\n",
    "    \n",
    "    conf_matrix = confusion_matrix(labels, pred_label)\n",
    "\n",
    "    ax = sns.heatmap(conf_matrix, \n",
    "                cmap='Blues', \n",
    "                xticklabels=CLASES, \n",
    "                yticklabels=CLASES,\n",
    "                annot=True,\n",
    "                fmt='d')\n",
    "\n",
    "    plt.xlabel('Predicted class') \n",
    "    plt.ylabel('True class') \n",
    "    \n",
    "    print(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c2a51e",
   "metadata": {},
   "source": [
    "#### Entrenamiento y evaluación  \n",
    "Para este análisis decidimos definir y evaluar diversas redes neuronales.\n",
    "\n",
    "En un principio definimos una red MLP con determinados parámetros, y en base a ella, probamos otras redes a las cuales les fuimos modificando diversas características como cantidad de capas y de neuronas, cantidad de épocas, tamaño del batch, tipo de función de activación, nivel de dropout, etc. \n",
    "\n",
    "Luego a la primer red MLP le agregamos una capa convolucional con ciertas características y así poder probar diversas redes de tipo convolucional, cambiando cantidad de filtros, tamañano del kernel, strides, cantidad de capas convolucionales, padding, entre otras cosas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700a422b",
   "metadata": {},
   "source": [
    "#### REDES NEURONALES 1, 1-a y 1-b\n",
    "La red 1 obtuvo valores de accuracy por encima del 70%, tanto para train como para test, ya en la primera época. Este valor fue aumentando hasta alcanzar un accuracy superior al 90% para train y al 87% para test en la última época.  \n",
    "Además, al observar la curva de aprendizaje, podemos corroborar que no hay sobreentrenamiento, ya que la diferencia del accuracy en train y test, es tan solo del 3% aproximadamente. Sin embargo, a medida que pasan las épocas, estas líneas parecen ir separándose, por lo cual entrenamos una red (1-a) con las mismas características, pero con 80 épocas. Tras analizar la curva de aprendizaje de esta última, comprobamos que el error creció y que la distancia entre las líneas de train y test continúa aumentando, lo cual, si bien sube más los valores del accuracy en test, podría llegar a generar algo de sobreentrenamiento si continuamos agregando épocas.  \n",
    "También decidimos probar a entrenar la red con un batch más pequeño (1-b) y evaluar las medidas obtenidas, pero notamos que no hubo grandes modificaciones en el accuracy. En general, de los 3 casos, hasta ahora, el mejor es el primero, ya que se obtuvo un accuracy mayor en el set de test.  \n",
    "Con respecto a las matrices de confusión, podemos ver que, son bastante similares en los 3 casos. En general, si bien hay muchos aciertos, también hay predicciones erróneas, pero en las clases de prendas que son similares (remera y camisa, botas y zapatillas, por ejemplo), lo cual tiene sentido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03afe26",
   "metadata": {},
   "source": [
    "##### Red Neuronal 1:\n",
    "* Tipo: MLP.\n",
    "* Capas: 3 densas, con 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en la primeras capas y 'softmax' en la de salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_1 = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307b514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_mlp_1 = model_mlp_1.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4be90a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e974a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_1, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_1, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad236f31",
   "metadata": {},
   "source": [
    "##### Red Neuronal 1-a:\n",
    "* Tipo: MLP.\n",
    "* Capas: 2 densas, con 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en la primer capa y 'softmax' en la de salida.\n",
    "* **Épocas: 80.**\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778a52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_1a = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_1a.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_1a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62288b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_1a = model_mlp_1a.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=80,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27140548",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0357148f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_1a, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_1a, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091613f3",
   "metadata": {},
   "source": [
    "##### Red Neuronal 1-b:\n",
    "* Tipo: MLP.\n",
    "* Capas: 2 densas, con 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en la primer capa y 'softmax' en la de salida.\n",
    "* Épocas: 25.\n",
    "* **Tamaño del batch: 125.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437b9abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_1b = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_1b.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_1b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80548d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_1b = model_mlp_1b.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=125,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd6708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e785963",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_1b, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_1b, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691f16d0",
   "metadata": {},
   "source": [
    "#### REDES NEURONALES 2, 2-a y 2-b  \n",
    "Para la red 2, mantuvimos los valores de la red 1, a excepción del número de capas y neuronas, que decidimos aumentar. Tras el entrenamiento, esta obtuvo una diferencia mayor en el accuracy con respecto a la red 1 en ambos sets. Además, podemos ver que el error, para esta red con más parámetros, disminuyó.  \n",
    "Tras modificar la cantidad de épocas en el entrenamiento (red 2-a), también pudimos comprobar que, si bien aumentaba la métrica en train, esta comenzaba a alejarse de los valores de test, confirmando nuevamente que si continuáramos agregando épocas, podría llegar a sobreentrenar.  \n",
    "Por otra parte, decidimos probar una red con mucha más cantidad de capas y neuronas (2-b). Tras entrenarla, comprobamos que tan solo en 10 épocas el accuracy llegaba a valores del 10%, lo cual indica que tener una gran cantidad de parámetros no es bueno, tal y como vimos en la teoría. Esto también se puede comprobar en las matrices de confusión, ya que la red solo predice Shirt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707ac4e6",
   "metadata": {},
   "source": [
    "##### Red Neuronal 2:\n",
    "* Tipo: MLP.\n",
    "* **Capas: 10 densas, con 60, 60, 60, 60, 40, 40, 40, 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la de salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7404136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_2 = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),   \n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373d1fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_2 = model_mlp_2.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b287578",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa3cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_2, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_2, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f32b7",
   "metadata": {},
   "source": [
    "##### Red Neuronal 2-a:\n",
    "* Tipo: MLP.\n",
    "* **Capas: 10 densas, con 60, 60, 60, 60, 40, 40, 40, 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la de salida.\n",
    "* **Épocas: 80.**\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296e783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_mlp_2a = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),   \n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_2a.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_2a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03b5bd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_mlp_2a = model_mlp_2a.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=80,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d10987",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27079c4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_2a, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_2a, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed167a",
   "metadata": {},
   "source": [
    "##### Red Neuronal 2-b:\n",
    "* Tipo: MLP.\n",
    "* **Capas: 31 densas, 3 de 200 neuronas, 7 de 120, 6 de 100, 5 de 80, 4 de 60, 3 de 40, 2 de 20 y la última de 10 neuronas, en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la de salida.\n",
    "* **Épocas: 10.**\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f5f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_2b = Sequential([\n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(200, activation='tanh'),\n",
    "    Dense(200, activation='tanh'),\n",
    "    Dense(200, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(120, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(100, activation='tanh'),\n",
    "    Dense(80, activation='tanh'),\n",
    "    Dense(80, activation='tanh'),\n",
    "    Dense(80, activation='tanh'),\n",
    "    Dense(80, activation='tanh'),\n",
    "    Dense(80, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),\n",
    "    Dense(60, activation='tanh'),   \n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(40, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_2b.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_2b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83a7ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_2b = model_mlp_2b.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10127b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b43ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_2b, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_2b, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eddef3",
   "metadata": {},
   "source": [
    "#### RED NEURONAL 3:  \n",
    "En esta red, con respecto a la primera, decidimos modificar la función de activación de las capas ocultas, reemplazando ‘tanh’ por ‘relu’, para evaluar si genera alguna diferencia. Tras el entrenamiento comprobamos que este cambio no generó mejores resultados, ya que el accuracy, tanto en train como en test, se redujo. También vimos que aumentó el error.    \n",
    "* Tipo: MLP.\n",
    "* Capas: 3 densas, con 20, 20 y 10 neuronas en ese orden.\n",
    "* Dropout: no aplica.\n",
    "* **Función de activación: 'relu' en la primeras capas y 'softmax' en la de salida.**\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_3 = Sequential([\n",
    "    \n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_3.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed56eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_3 = model_mlp_3.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2555398",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a680b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_3, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_3, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466466c5",
   "metadata": {},
   "source": [
    "#### RED NEURONAL 4:  \n",
    "Para esta red, mantuvimos los valores de la red 1, a excepción del dropout, ya que decidimos aplicarle un 30% y analizar los resultados. Luego de entrenar, verificamos que esta modificación empeoró los valores del accuracy tanto para train, como para test. También vimos que aumentó el error.  \n",
    "* Tipo: MLP.\n",
    "* Capas: 3 densas, con 20, 20 y 10 neuronas en ese orden.\n",
    "* **Dropout: 30% en capas ocultas.**\n",
    "* Función de activación: 'tanh' en la primeras capas y 'softmax' en la de salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e6e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_4 = Sequential([\n",
    "    \n",
    "    Flatten(input_shape=(28, 28, 1)),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_mlp_4.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_mlp_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14351648",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mlp_4 = model_mlp_4.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f195032",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_mlp_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc001b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_mlp_4, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_mlp_4, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f8d515",
   "metadata": {},
   "source": [
    "#### RED NEURONAL 5:  \n",
    "Esta red presenta las mismas características que la red 1, pero con la diferencia de que ahora incluye una capa convolucional de 4 filtros de 2x2 y stride 1. Esto hizo que el accuracy sea el mayor hasta ahora, con respecto a las demás redes analizadas, es decir que mejora el valor de la métrica. Además, también hizo que se redujera el error con respecto a dichas redes.  \n",
    "* **Tipo: Convolucional.**\n",
    "* **Capas: 1 convolucional con 4 filtros de 2x2 y stride 1, un max pooling de 2x2 y 3 densas, con 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a464a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_1 = Sequential([\n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=4, kernel_size=(2, 2), strides=1, activation='tanh'), \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13563ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_1 = model_conv_1.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29542dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_1, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_1, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa60b18b",
   "metadata": {},
   "source": [
    "#### RED NEURONAL 6:  \n",
    "Basándonos en la red 5, decidimos probar una red que modifique la cantidad de filtros de la capa de convolución, que ahora pasará de 4 a 8. Este cambió generó un aumento del accuracy con  respecto a la capa anterior, por lo cual consideramos que tener más filtros, en este caso, podría llegar a ser una mejor opción. Además, también hizo que se redujera considerablemente el error, inclusive más que la red anterior.  \n",
    "* Tipo: Convolucional.\n",
    "* **Capas: 1 convolucional con 8 filtros de 2x2 y stride 1, un max pooling de 2x2 y 3 densas, con 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8e4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_2 = Sequential([    \n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=8, kernel_size=(2, 2), strides=1, activation='tanh'), \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc96461",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_2 = model_conv_2.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc4323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0f5b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_2, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_2, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91908e26",
   "metadata": {},
   "source": [
    "#### RED NEURONAL 7:  \n",
    "Basándonos en la red 5, también decidimos probar una red que modifique el tamaño de los filtros de la capa de convolución, que ahora pasará de 4x4 a 8x8. Este cambió bajó, en muy pequeña medida, el valor del accuracy con respecto a las anteriores, por lo que podríamos decir que esta modificación, no aporta grandes mejoras. También podemos mencionar que, si bien, reduce un poco el error, este valor no es significativo respecto al error de las demás redes.  \n",
    "* Tipo: Convolucional.\n",
    "* **Capas: 1 convolucional con 4 filtros de 8x8 y stride 1, un max pooling de 2x2 y 3 densas, con 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20070dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_3 = Sequential([\n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=4, kernel_size=(8, 8), strides=1, activation='tanh'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_3.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9931b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_conv_3 = model_conv_3.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce995f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af5c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_3, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_3, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935b6e5c",
   "metadata": {},
   "source": [
    "#### RED NEURONAL 8:  \n",
    "A partir de la red 5, también decidimos probar una red que modifique el stride de la capa de convolución, que ahora pasará de 1 a 2. Este cambió no aportó una mejora significativa con respecto al accuracy de las redes anteriores, ya que puntualmente, presenta casi el mismo valor que la red 1. También podemos mencionar que, si bien, reduce un poco el error, este valor no es significativo respecto al error de las demás redes.  \n",
    "* Tipo: Convolucional.\n",
    "* **Capas: 1 convolucional con 4 filtros de 2x2 y stride 2, un max pooling de 2x2 y 3 densas, con 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_4 = Sequential([\n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=4, kernel_size=(2, 2), strides=2, activation='tanh'), \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_4.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd0ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_4 = model_conv_4.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c904c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e1b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_4, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_4, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2107cf8d",
   "metadata": {},
   "source": [
    "#### RED NEURONAL 9:  \n",
    "Basándonos en la red 5, también decidimos probar una red que rellene la entrada con 0, es decir, utilizar padding. Este cambió mejoró, en muy pequeña medida, el valor del accuracy con respecto a la red 1 pero no con respecto a todas las anteriores, por lo que podríamos decir que esta modificación, no aporta grandes mejoras. También podemos mencionar que reduce considerablemente el error, con respecto al de las demás redes, pero no más que la red 6.  \n",
    "* Tipo: Convolucional.\n",
    "* **Capas: 1 convolucional con 4 filtros de 2x2, stride 1 y padding, un max pooling de 2x2 y 3 densas, con 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df363f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_5 = Sequential([\n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=4, kernel_size=(2, 2), strides=1, padding='same', activation='tanh'), \n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_5.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c264b54e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_conv_5 = model_conv_5.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5aa83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf1da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_5, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_5, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f099a5b4",
   "metadata": {},
   "source": [
    "#### RED NEURONAL 10:  \n",
    "Quizás trabajar con una sola capa convolucional es poco, así que decidimos probar una red que agregue más de una capa de convolución. Ahora trabajaremos con 3 capas en lugar de 1. Estas tendrán las mismas características que la red 5. Tras el entrenamiento podemos ver que este cambio aportó una suba en el valor de la métrica con respecto a dicha red 5, por lo cual es un factor a tener en cuenta a la hora de “mejorar” una red. Además, también hizo que se redujera considerablemente el error, casi al nivel de la red 6.  \n",
    "* Tipo: Convolucional.\n",
    "* **Capas: 3 convolucionales con 4 filtros de 2x2 y stride 1, un max pooling de 2x2 y 3 densas, con 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76447a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_6 = Sequential([\n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=4, kernel_size=(2, 2), strides=1, activation='tanh'),\n",
    "    Convolution2D(filters=4, kernel_size=(2, 2), strides=1, activation='tanh'), \n",
    "    Convolution2D(filters=4, kernel_size=(2, 2), strides=1, activation='tanh'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_6.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0438622",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_6 = model_conv_6.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e4ae5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14676674",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_6, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_6, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e1e835",
   "metadata": {},
   "source": [
    "#### RED NEURONAL 11:  \n",
    "Para esta red, decidimos aplicar aquellos cambios que consideramos que, por los análisis anteriores, mejoraban en mayor medida, los valores del accuracy y del error, como por ejemplo, agregar más capas y aumentar la cantidad de filtros por capa. Estos cambios, confirmaron que aplicarlos, genera mejores resultados, ya que de todas las redes probadas, es la que mayor valor de accuracy obtuvo. Aunque cabe aclarar que no es una diferencia tan grande, sobre todo con respecto a la red 6. También podemos mencionar que redujo considerablemente el error, pero no más que dicha red 6. Podemos decir que con solo agregar más filtros podría ser suficiente para obtener buenos valores. Con respecto a la curva de aprendizaje, podemos ver que a medida que avanzan las épocas, las líneas de train y test se separan cada vez más, por lo cual si agregaríamos más épocas, el modelo podría llegar a sobreentrenar.  \n",
    "* Tipo: Convolucional.\n",
    "* **Capas: 4 convolucionales, 1 con 16 filtros y 3 con 8 filtros de 2x2 y stride 1, un max pooling de 2x2 y 3 densas, con 20, 20 y 10 neuronas en ese orden.**\n",
    "* Dropout: no aplica.\n",
    "* Función de activación: 'tanh' en cada capa y 'softmax' en la salida.\n",
    "* Épocas: 25.\n",
    "* Tamaño del batch: 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f4751",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_7 = Sequential([\n",
    "    Convolution2D(input_shape=(28, 28, 1), filters=16, kernel_size=(2, 2), strides=1, activation='tanh'),\n",
    "    Convolution2D(filters=8, kernel_size=(2, 2), strides=1, activation='tanh'), \n",
    "    Convolution2D(filters=8, kernel_size=(2, 2), strides=1, activation='tanh'),\n",
    "    Convolution2D(filters=8, kernel_size=(2, 2), strides=1, activation='tanh'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(20, activation='tanh'),\n",
    "    Dense(len(CLASES), activation='softmax'),\n",
    "])\n",
    "\n",
    "model_conv_7.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "    \n",
    "model_conv_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aef45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_conv_7 = model_conv_7.fit(\n",
    "    x_train_r,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=250,\n",
    "    validation_data=(x_test_r, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1590445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curva_aprendizaje(history_conv_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad555aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_7, x_train_r, y_train, 'Matriz de confusión - Train')\n",
    "matriz_confusion(model_conv_7, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75527db3",
   "metadata": {},
   "source": [
    "##### Aumentación de datos  \n",
    "Para probar esta técnica elegimos el modelo que mayor valor de accuaracy obtuvo en train, es decir, la red 11, que agregaba más capas convolucionales y más filtros. Para modificar las imágenes, alteramos parámetros como el ángulo de rotación, nivel de desplazamiento horizontal y vertical, brillo, espejar horizontalmente la imagen, y nivel de aumento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c84f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos un dataset de train con imagénes alteradas\n",
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=(0.5, 1.5),\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    zoom_range=0.1,\n",
    ")\n",
    "\n",
    "train_alterado = data_generator.flow(\n",
    "    x_train_r.reshape(60000,28,28,1),\n",
    "    y_train,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62f7293",
   "metadata": {},
   "source": [
    "Podemos ver algunos ejemplos de las imágenes modificadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10d32e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imagenes_a, etiquetas_a = train_alterado.next()\n",
    "mostrar_imagenes(imagenes_a, etiquetas_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b3712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converter_dataset = ImageDataGenerator()\n",
    "#train_no_alterado = converter_dataset.flow(x_train_r.reshape(60000,28,28,1), y_train, shuffle=False)\n",
    "#imagenes, etiquetas = train_alterado.next()\n",
    "#train_ampliado_imagenes = np.concatenate(imagenes_a + x_train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iter = (i for i in train_ampliado_imagenes)\n",
    "#sum(1 for _ in iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4251408",
   "metadata": {},
   "source": [
    "### 3) Conclusiones. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b88ec42",
   "metadata": {},
   "source": [
    "##### Desempeño del modelo por clase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c7f2df",
   "metadata": {},
   "source": [
    "Para evaluar el desempeño de un modelo por clase, elegimos la red 11, es decir, la misma que utilizamos para hacer aumentación de datos, ya que era la que mayor valor de accuracy obtenía.  \n",
    "A partir de la matriz de confusión del modelo, podemos ver que este tiene un muy buen desempeño, mantiendo la mayoría de las predicciones en la categoría correcta, exceptuando casos en los que se confunde prendas que son bastante similares como: T-shirt/top y Shirt, Pullover y Coat, Coat y Shirt, entre otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45421247",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion(model_conv_7, x_test_r, y_test, 'Matriz de confusión - Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dfe774",
   "metadata": {},
   "source": [
    "##### Aciertos y desaciertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16372765",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_conv_7.predict(x_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb292c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(CLASES[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                CLASES[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array, true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para mostrar casos de aciertos y desaciertos\n",
    "def mostrar_aciertos_desaciertos(clase, acierto):\n",
    "    count = 0\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        if(acierto==1):\n",
    "            if(CLASES[np.argmax(prediction)]==CLASES[y_test[i]]):\n",
    "                if(clase==CLASES[np.argmax(prediction)]):\n",
    "                    count+=1            \n",
    "                    plt.figure(figsize=(4,2))\n",
    "                    plt.subplot(1,2,1)\n",
    "                    plot_image(i, prediction, y_test, x_test_r)\n",
    "                    plt.subplot(1,2,2)\n",
    "                    plot_value_array(i, prediction,  y_test)\n",
    "                    plt.show()\n",
    "        else:\n",
    "            if(CLASES[np.argmax(prediction)]!=CLASES[y_test[i]]):\n",
    "                if(clase==CLASES[y_test[i]]):\n",
    "                    count+=1            \n",
    "                    plt.figure(figsize=(4,2))\n",
    "                    plt.subplot(1,2,1)\n",
    "                    plot_image(i, prediction, y_test, x_test_r)\n",
    "                    plt.subplot(1,2,2)\n",
    "                    plot_value_array(i, prediction,  y_test)\n",
    "                    plt.show()\n",
    "        if(count==2):\n",
    "            break           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfa33f9",
   "metadata": {},
   "source": [
    "###### T-shirt/top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7647137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('T-shirt/top', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e8f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('T-shirt/top', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad4f8d2",
   "metadata": {},
   "source": [
    "###### Trouser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa09f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Trouser', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15244c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Trouser', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746fa06a",
   "metadata": {},
   "source": [
    "###### Pullover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4baad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Pullover', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c654e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Pullover', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c9b986",
   "metadata": {},
   "source": [
    "###### Dress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793479ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Dress', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb9da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Dress', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639e26ec",
   "metadata": {},
   "source": [
    "###### Coat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd29ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Coat', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed95f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Coat', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3844de3",
   "metadata": {},
   "source": [
    "###### Sandal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Sandal', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb6b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Sandal', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c1b5a6",
   "metadata": {},
   "source": [
    "###### Shirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5409136",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Shirt', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13065259",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Shirt', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c571b92",
   "metadata": {},
   "source": [
    "###### Sneaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768be92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Sneaker', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Sneaker', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515e7304",
   "metadata": {},
   "source": [
    "###### Bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5111c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Bag', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Bag', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ec140c",
   "metadata": {},
   "source": [
    "###### Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ffc397",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Ankle boot', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32919fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_aciertos_desaciertos('Ankle boot', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef167653",
   "metadata": {},
   "source": [
    "##### Casos reales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af572046",
   "metadata": {},
   "source": [
    "Decidimos probar el modelo con otras imágenes de prendas, fuera del dataset. Como podemos ver las predicciones no fueron muy buenas, ya que de 4 casos, solo acertó un caso y con una probabilidad baja.  \n",
    "Esto puede indicarnos que el modelo funciona bien solo con las imágenes del dataset, es decir que de alguna manera, está sobreentrenando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43994b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para mostrar una imagen de ropa y predecir su tipo\n",
    "def mostrar_predecir(image_path):\n",
    "    image_array = img_to_array(load_img(image_path, grayscale=True, target_size=(28, 28)))\n",
    "    inputs = np.array([image_array])\n",
    "    predictions = model_conv_2.predict(inputs)\n",
    "    display(Image(image_path, width=150))\n",
    "    print(\"Prediction:\", CLASES[np.argmax(predictions)])\n",
    "    print(\"Prediction detail:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390d07ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_predecir(\"./ropa/Shirt.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba78fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_predecir(\"./ropa/Ankle_boot.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5718a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_predecir(\"./ropa/Bag.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79584df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_predecir(\"./ropa/Trouser.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
