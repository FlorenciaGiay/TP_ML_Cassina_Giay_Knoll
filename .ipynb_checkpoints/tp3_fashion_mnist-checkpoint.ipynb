{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0404b47",
   "metadata": {},
   "source": [
    "# Redes Neuronales\n",
    "## Fashion detector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7680cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# de python, para especificar rutas de archivos y directorios\n",
    "from pathlib import Path\n",
    "\n",
    "# lib para trabajar con arrays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# lib que usamos para mostrar las imágenes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# libs que usamos para construir y entrenar redes neuronales, y que además tiene utilidades para leer sets de\n",
    "# imágenes\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# libs que usamos para tareas generales de machine learning. En este caso, métricas\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# configuración para que las imágenes se vean dentro del notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cb1398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "CATEGORIAS = \"T-shirt/top\" , \"Trouser\" , \"Pullover\" , \"Dress\" , \"Coat\" , \"Sandal\" , \"Shirt\" , \"Sneaker\" , \"Bag\" , \"Ankle boot\"\n",
    "##TRAIN_DIR = Path('./')\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e628a3",
   "metadata": {},
   "source": [
    "### 1) Análisis exploratorio sobre el conjunto de datos.  \n",
    "Este es un dataset de 70000 imágenes en blanco y negro de 28x28 pixeles, de 10 categorías de prendas, divididas en un set de train con 60000 imágenes y otro de test de 10000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e6bcec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Cantidad y tamaño de imágenes de train:')\n",
    "x_train.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c3f0d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Cantidad y tamaño de imágenes de test:')\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f736392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diccionario de tipos que contiene:\n",
    "# clave (salida): [nombre prenda, cantidad train, cantidad test]\n",
    "CLASES = {\n",
    "    0: [\"T-shirt/top\", 0, 0],\n",
    "    1: [\"Trouser\", 0, 0],\n",
    "    2: [\"Pullover\", 0, 0],\n",
    "    3: [\"Dress\", 0, 0],\n",
    "    4: [\"Coat\", 0, 0],\n",
    "    5: [\"Sandal\", 0, 0],\n",
    "    6: [\"Shirt\", 0, 0],\n",
    "    7: [\"Sneaker\", 0, 0],\n",
    "    8: [\"Bag\", 0, 0],\n",
    "    9: [\"Ankle boot\", 0, 0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d927cb5a",
   "metadata": {},
   "source": [
    "Las categorías de prendas son las siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25f917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clave in CLASES:\n",
    "    print(CLASES[clave][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16fd149",
   "metadata": {},
   "source": [
    "Ejemplos de la imágenes sin modificaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef0dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(nombres[y_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21393a83",
   "metadata": {},
   "source": [
    "A partir de los gráficos siguientes, podemos notar que el set de datos está completamente balanceado tanto en train como test. En el set de train, hay 6000 imágenes de cada tipo de prenda, mientras que en el set de test hay 1000 imágenes de cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929ecb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cantidades = []\n",
    "nombres = []\n",
    "\n",
    "# función para contar y graficar la cantidad de prendas por tipo\n",
    "def distribucion(salidas, posicion, titulo=''):\n",
    "    for salida in salidas:\n",
    "        CLASES[salida][posicion] += 1\n",
    "        \n",
    "    for clave in CLASES:\n",
    "        cantidades.append(CLASES[clave][posicion])\n",
    "        nombres.append(CLASES[clave][0])\n",
    "    display(titulo)\n",
    "    plt.pie(cantidades, labels=nombres, autopct=\"%0.1f %%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c445f31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distribucion(y_train, 1, 'Distribución de train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c12f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distribucion(y_test, 2, 'Distribución de test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e16543",
   "metadata": {},
   "source": [
    "### 2) Machine Learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d96a49",
   "metadata": {},
   "source": [
    "##### Reescalar imágenes  \n",
    "En primera instancia reescalamos los valores de las imágenes, tanto en test como en train. Esto se puede comprobar en los siguientes gráficos que muestran el rango de valores que posee una imagen del dataset antes y después de reescalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80dd471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reescalamos los valores de las imágenes\n",
    "x_train_r = x_train/ 255.0\n",
    "y_test_r = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf421f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Antes de escalar:')\n",
    "plt.figure()\n",
    "plt.imshow(x_train[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56078ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Después de escalar:')\n",
    "plt.figure()\n",
    "plt.imshow(x_train_r[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58433a79",
   "metadata": {},
   "source": [
    "##### Modificar el tamaño de las imágenes \n",
    "En cuanto al tamaño de las imágenes, optamos por NO modificarlo, debido a que ya es lo suficientemente pequeño como para entrenar sin demorar demasiado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
